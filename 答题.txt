1.	谈一下你对微服务的理解
	我对微服务的理解是这样的，因为以前的应用架构大部分是传统的单体架构。单体架构虽然在项目开始时，体量小，开发测试方便，部署也只需要一个war包等这些优点。但是后续数据量的增大，业务的复杂，随着不断的迭代，单独的一个服务会变得越来越臃肿，业务的耦合度会越来越高，造成后续难以维护，难以扩展。
	所以引入了微服务架构来缓解单体架构的这些缺陷。微服务架构主要是将整个系统按照业务或者功能，划分成一个个单独的服务，这一个个单独的服务就是微服务。现在各个系统的数据量，并发量，业务都比较大，微服务架构还是很契合这种情况。
	微服务架构有很多的优点：
		内聚解耦：因为整个系统被按照业务或者功能拆分成了一个个的微服务，所以每个微服务个体是高度内聚的，整个系统实现了一定程度的解耦。每个微服务可以更专注于自身的业务功能，尽量避免收到其他模块的影响。
		故障隔离：微服务发生了故障时，其他服务几乎不受影响，整个系统也不会因为某个微服务的故障，产生较大的连锁故障。
		有选择性的扩展：因为拆分成了一个个微服务，所以可以更加有针对性的进行扩展。我们可以有选择性的对A微服务进行扩机器，不像单体应用那样，只能整体的进行扩展。
		新技术升级：技术的选择上也可以实验更多的新技术，可以现在几个微服务上实验新技术，如果后续稳定的话在实施到整个系统上。
	微服务架构相对于单体架构来说，其本身的复杂度就会带来一些学习成本和新的难题：
		运维部署会比较复杂：单体架构可能只需要一个war就能部署起来一个系统，但是微服务架构因为有很多微服务，每个微服务都是一个war包，如果再算上集群的话，每个微服务又会有很多节点。所以一个微服务系统的部署可能需要部署成百上千的war包，那么后续的运维，监控等工作量也会急剧增大。
		测试起来比较麻烦：不像单体服务那样，只需要起一台本地服务，测起来效果很直观。微服务架构可能需要起多台服务进行测试，甚至因为配置环境等问题，只能到特定环境进行测试开发。
		通信成本：某个业务功能很可能需要多个微服务互相配合实现，每个微服务相当于一个进程，那么这种跨进程的通信相对于单体服务而要就需要额外的通信成本。不像单体架构那样，模块间的通信只需要函数调用或者模块间的依赖即可。

2.	什么是SpringCloud
	SpringCloud是分布式微服务架构的一套整体解决方法，提供了快速构建微服务系统的各种组件工具，比如注册中心，配置中心，服务调用，负载均衡，网关等组件。SpringCloud有两种常见的技术栈，SpringCloudNetflix和SpringCloudAlibaba

3.	谈一谈你对注册中心的理解
	因为对于微服务架构而言，大部分的业务功能都需要多个微服务相互配合完成的。那么各个微服务之间肯定是需要进行跨进程通信交互的，这个时候上游的微服务就需要知道下游微服务的地址端口信息，是否健康，有哪些可用节点等这些元信息。
	这些功能是和业务无关的，所以最好能有一个专门的组件来做这些事情，这个组件就是注册中心。将这些功能抽取出来交给注册中心来实现，一定程度实现了解耦，各个微服务可以更见专注于自身功能的开发。
	注册中心主要提供了如下功能：
		服务注册：当有服务新增时，会到注册中心进行注册，注册中心会维护该服务的ip端口，健康状态等元信息。同时当有服务下线时，注册中心也会及时的下线该服务的注册信息。
		服务发现：每个服务都会将自身的元信息注册到注册中心上，后续当有服务需要这些信息时，就可以从注册中心动态的获取到这些信息。所以即使后续有服务的地址信息发生了变化，调用发起者也不需要做额外的动作，从注册中心拿到最新的注册信息即可。
		健康状态：注册中心可以及时的监控到服务故障和不可用，进而更新服务的健康信息，避免调度到不健康的服务。
		解耦：因为这些功能都是独立于业务外的，所以交给注册中心专门完成，实现了和业务代码的解耦，微服务可以更专注于自身的功能开发

4.	说一下你对nacos的理解
	nacos是阿里开源的注册中心，他的功能还是比较强大的，他既可以做注册中心，也可以做配置中心。所以如果选型nacos的话，可以避免再引入配置中心组件。
	而且nacos的一致性协议既可以是AP架构，也可以一定程度上实现CP架构，这一点主要是通过ephemeral临时实例这个配置来控制的。如果是临时实例注册，nacos集群的一致性协议主要是AP架构，此时nacos-server节点没有主从区分，注册信息主要在内存中维护。AP架构的nacos可能会牺牲短时间的不一致性（各个nacos-server节点虽然会有短时间的数据不一致的情况），但是尽量保证高可用，高并发。
	如果是非临时实例，那么nacos集群是CP架构，此时的nacos节点会有主从之分，主节点主要进行注册，注销等写操作，从节点会定时的同步主节点中的注册信息。此时nacos会将注册信息写到安装目录的data目录下。CP架构会尽量保证nacos节点间的数据一致性，但是吞吐量会受到影响。
	nacos注册中心的使用，主要是部署nacos的server端，然后微服务引入nacos-discovery包作为client端。通过yml配置文件指定nacos注册中心地址，就可以在微服务启动时将自身注册到nacos-server中。
	nacos中注册的服务，如果不在同一个namespace，group配置下是不能进行通信的。
	nacos他有一套opneapi，比如服务注册，心跳检查，集群节点同步等，nacos底层会依靠这些api进行通信和功能实现

5.	nacos注册服务
	首先服务需要引入nacos-discovery包作为nacos客户端。当服务启动时，nacos的自动配置类NacosDiscoveryAutoConfiguration会注册几个配置Bean：比如根据yml文件中的nacos.discovery前缀配置生成的Instance Bean对象，就是当前服务实例。
	还有注册一个XxxAutoRegistration的Bean，这个Bean实现了ApplicationListener，所以本质上是一个事件监听器，监听的事件是WebServerInitializedEvent。当Spring容器启动后，Spring会发送一个这个事件，+，然后在它的监听回调方法中进行服务实例注册。
	客户端中具体的注册动作主要做了两件事
	如果当前注册实例是临时实例的话，那么nacos客户端会开启一个延时定时任务，这个定时任务主要是客户端会在5s后，每隔5s向服务端发送一次心跳，告诉服务端我还活着，服务端会更新一下最新的心跳时间戳等信息。具体的发送心跳动作也是通过一个http请求发送的
	然后通过Http调用一个nacos公开的注册接口，将根据配置文件生成的注册实例Bean做一下加工，然后作为接口参数。
	
	nacos-server端收到这个注册请求，会进行若干的注册动作。nacos-server端会做一系列的事情。
	当该namespace下的该serviceName是第一次注册，那么该服务会先完善一下注册表结构，注册表是一个双层map结构，最外层的key是namespace，value是一个内层map，内层map的结构是serviceName对应着service，这个service里面还有map成员属性，结构是cluster集群名-服务实例Set。
	因为这个service是第一次注册，会创建一个心跳检查定时任务。这个心跳定时任务的时间间隔是5000。首先会根据服务名的hash对机器数取模后，选择集群中的一个nacos节点执行该心跳检查定时任务。然后会拿到该namespace下，该serviceName下的所有实例。先判断上次心跳时间距离当前时间如果超过15s，那么会将其健康状态设置为false，并且发送事件给客户端告知有服务心跳超时。健康状态判断完后，会再次进行一轮判断，判断上次心跳时间距离现在如果超过30s，那么会直接将该服务下线，具体也就是调用服务下线接口。
	这个心跳检查定时任务是延时异步执行的，nacos-server在提交这个任务后，继续执行后续的服务注册的逻辑。nacos会把要注册实例经过包装后，塞到一个阻塞队列中。会有一个SpringBean，通过@PostConstruct定义一个init方法，在init方法里面提交一个异步线程，这个线程会一直循环，从阻塞队列中获取任务，如果从阻塞队列中拿到任务，那么就将注册信息放到内存中的注册表里。之后会在发送一个服务变化事件，事件监听者在监听回调里面会通过UDP协议发送服务列表有变化这一信息给客户端。主要是告诉客户端注册信息发生了变化，客户端本地缓存的注册信息应该及时拉取更新。客户端收到这个UDP事件后，会返回一个AKC信号，如果服务端没有收到AKC信号，会重新发送。虽然UDP通信不能保证消息的可靠性，首先udp事件有重试机制，而且nacos客户端会开启定时任务，每个一段时间更新客户端缓存的服务列表，有定时任务更新服务列表作为兜底，所以不用担心数据不会更新的情况。而且相较于zk的和客户端建立长连接进行通信，udp的开销和效率要高很多。
（UDP端口怎么来的，是客户端在从服务端拉取服务列表是，作为参数传递给服务端的，方便后续服务列表发生变化时，通过udp端口进行通知）
	nacos在将本次要注册的服务放到注册表后，会再次提交一个异步任务，通过http接口同步这次注册信息给其他nacos节点。

6.	nacos的服务发现
	nacos客户端在进行服务间调用时，会先尝试从本地缓存在获取服务列表，如果服务列表没有的话，那么会通过一个http请求，请求到服务端拉取服务端最新的注册信息得到服务列表。
	而且nacos客户端还会开启一个定时任务，定时到nacos服务端拉取最新的服务列表更新到本地。

7. 	nacos集群
	nacos集群节点之间会通过集群节点状态同步任务，互相同步节点状态，如果某节点宕机了，集群中的其他节点能及时感知到。nacos健康节点数量会影响到心跳检测定时任务执行机器的选择。什么时候执行这个延迟定时任务，也是在一个配置Bean初始化完成后，通过postconstruct注解的init方法，提交的该任务，第一次延迟时间是2s，每隔2s执行一次。	
	注册服务实例信息在nacos集群的各个节点中也会定时同步，也是通过一个定时任务。同步的发起机器就是做健康检查任务的那台机器。

8.	nacos的选举过程
	cp架构nacos集群的leader选举过程也是由一个定时任务来完成的。
	首先每个nacos-server节点有一个选举间隔时间最开始是一个0-15s的随机数，定时任务的间隔时间是200ms，每执行一次定时任务都会将选举间隔减去定时任务间隔，当选举间隔小于0时，就开始leader选举了。因为每个节点的选举间隔时间都是随机不同的，多个nacos节点肯定有一个会先到期，开始选举
	先重置选举时间，此时选举时间间隔是15-20s的随机数。重置集群同步数据心跳的时间间隔为5s。
	发起leader投票，重置leader为null和投票数，首先选举周期+1，然后投票给自己，定义自己是leader候选者，发送投票信息给其他节点。其他节点收到信息后，会比对候选节点的选举周期，如果选举周期大于自己，那么就同意候选者为leader，投他一票，然后重置自己的选举时间，并且更新选举周期为收到的选举周期。如果选举周期小于自己，那么就不会投他，而是投自己。
	然后候选者收到所有其他节点的响应后，遍历响应，判断选票是否超过半数：超过设为leader

9.	nacos的cp原理
	注册实例时，如果是非临时实例，会先判断当前nacos-server节点是不是leader节点。如果会将该次注册请求转发给leader节点。然后leader节点执行注册动作，会将注册信息写到磁盘，也将注册信息更新到内存的注册表中。然后同步实例信息给其他的nacos的节点，用CountDownLatch实现了一个逻辑，只有当半数以上的nacos节点同步成功后，才会任务注册成功。同时发送服务列表变化事件给客户端，通知其拉取最新服务列表，更新本地缓存。
	而且CP架构的nacos集群，leader节点主要做写操作，follower节点会定期从leader节点同步注册信息。这个过程也是通过一个心跳任务进行的，只有leader会发送心跳，leader会将其注册表中的key经过压缩后发送给其他节点。其他节点收到后，会与本地缓存的服务列表进行比对，找出需要同步的，需要删除的，需要更新。然后follower节点会批量的从leader获取key对应的数据，然后更新到本地。这一步可以保证集群节点间数据的最终一致性。

10.	谈一下Ribbon及其原理
	Ribbon是SpringCloud技术栈中的负载均衡组件，而且是一个客户端负载均衡组件。它在服务间调用时，在调用者本地完成了负载均衡的动作，而Nginx是在中间进行一个集中的负载均衡，这是两者的区别。
	Ribbon底层主要是通过@LoadBalanced这个注解开进行工作的，如果没有使用Feign，而是用RestTemplate做一个服务间调用的，那么需要在我们定义RestTemplate类型Bean的地方加上@LoadBalanced注解，加上后Riboon会为我们开启两个主要的功能
	为我们开启客户端的负载均衡功能
	为我们做一个服务名和ip端口的映射，后续在进行服务调用时，在url中可以用服务名代替ip端口。
	
	大致的一个原理，@LoadBalanced注解是一个复合注解，其中还有@Qualifier子注解，所以@LoadBalanced也具有@Qualifier作用。所以当我们在注入RestTemplate属性时，可以通过@LoadBalanced注解指定只注入加了@LoadBalanced注解的RestTemplate类型的Bean。（属性注入的地方加上@LoadBalanced注解，RestTemplate类型Bean定义的地方加上@LoadBalanced注解）。那么就可以只针对加了@LoadBalanced注解的RestTemplate类型的Bean进行定制扩展动作。
	加了@LoadBalanced注解的RestTemplate：会有一个RestTemplateCustomizer专门针对RestTemplate的定制器，定制器的customize()方法逻辑，就是为传入的RestTemplate对象添加一个LoadBalancedInterceptor拦截器对象。然后在拦截器的intercept方法里面会对加了@LoadBalanced注解的RestTemplate类型的Bean做一些扩展，比如负载均衡，服务名和ip端口的映射。
	这些动作是在SmartInitializingSingleton接口的afterSingletonInstantized这个Spring的扩展点执行的。因为是在这个初始化后扩展点afterSingletonInstantized()方法里面做的添加拦截器，所以如果我们在其他扩展点使用RestTemplate那么就可能不具有负载均衡的功能。解决办法：我们在RestTemplate的Bean定义里，注入LoadBalancedInterceptor作为方法参数，然后手动加到RestTemplate类型的Bean里面。

11. Ribbon的负载均衡策略
	可以通过定义IRule类型的Bean，得到一个负载均衡策略，不过这样的效果是得到一个全局默认的负载均衡策略。也可以在yml做局部具体的负载均衡策略配置，为指定的微服务指定具体的负载均衡策略。
	Ribbon的默认负载均衡策略是轮询
	Round Robin轮询：默认的负载均衡策略，请求按照服务实例的顺序依次分配，每个实例接收的请求数量大致相等。
		每个实例的负载能力可能不一样，请求处理速度又快有慢，而且每个请求背后的业务复杂度也可能不一样，所以有这方法面的考量
	Randon随机：随机选择一个可用的服务实例来处理请求，这种策略使用于负载均衡不需要考虑后端服务性能活状态的情况。
	Weighted Random加权随机：根据每个服务实例的权重来选择，权重越高的实例被选中的概率越大，这允许您在不同的服务实例之间分配不同的负载。
	Weighted Response Time加权响应时间：根据每个服务实例的平均响应时间来选择，响应时间较短的实例被选中的概率较高，从而使得请求倾向于分配到响应更快的实例上。


12.	RPC的理解
	因为在分布式系统中，经常一个业务功能是需要多个微服务共同完成的，不像单体服务模块之间直接通过方法调用进行通信，这种情况就涉及到跨进程，跨机器的通信。
	这个时候就需要一种成熟的技术，既能够满足这种跨进程，跨机器的通信，还要效率高，并且使用方便。
	所以就有了RPC这个技术，它是一种实现分布式不同节点之间互相通信的技术。让分布式系统的节点能够像调用本地方法一样调用其他节点的资源。RPC技术通过隐藏底层的网络通信细节，让开发人员使用起来分厂简单，并且开发人员可以无需关心具体的底层通信细节，更加关注于业务功能的开发。

13.	Feign的原理
	Feign通过@FeignClient注解声明一些接口，通过@EnableFeignClients注解生效@FeignClient接口，后续我们在需要进行服务间调用的地方，注入@FeignClient接口，就可以直接使用@Feign接口来进行服务间的调用。
	具体Feign的原理或者说Feign和Spring的整合依赖@EnableFeignClients这个注解：为什么@FeignClient接口能被扫描得到BeanDefinition，生成SpringBean对象？按照我们的理解，Spring的默认扫描逻辑是不会扫描接口的，所以这里Spring和Feign的整合肯定有相关方面的定制。就像Spring和Mybatis的整合一样。
	@EnableFeignClients注解内部通过@Import注解引入了一个配置类FeignClientRegistrar，这个配置类实现了ImportBeanDefinitionRegistrar接口，这个接口中有个方法就是专门用来注册我们的BeanDefinition的。在这个方法中Feign自定义了一个扫描器并且结合IncludeFilter实现了一个扫描逻辑，可以将包路径下的@FeignClient接口扫描出来得到BeanDefinition。
	现在能够将@FeignClient接口扫描得到BeanDefinition，怎么根据接口生成Bean对象呢？这里借助了FactoryBean，在FactoryBean的getObject方法中通过JDK的动态代理得到@FeignClient对象的代理对象，因为Feign整合了Ribbon，这个代理对象其中的代理逻辑就有负载均衡，服务名IP端口映射等。最终我们注入的@FeignClient接口，就是这个代理对象。

14.	Feign的一些扩展功能
	日志配置（全局和局部服务配置）
	因为Feign默认使用的是JDK1.1的一个Http客户端，这个是很旧的Http客户端了，可以通过配置换成目前更高效的HttpClient，比如ApachHttpClient或者okHttp
	配置压缩

15.	Sentinel的一些流控规则
	流量控制主要有两种统计类型，一种是统计并发线程数，另一种则是统计QPS（每秒请求数）
	流控模式：直接，关联，链路
	流量控制：快速失败（直接拒绝），Warm up预热（对超出阈值的请求也会拒绝并抛出异常，但是这种模式的阈值会动态变化，阈值会缓慢增大），匀速排队（请求会排队等待）

16.	介绍一下Kafka及你们公司使用Kafka的场景
	Kafka是一个天然支持分布式，具有该吞吐量，高并发，低延迟的一个消息中间件。Kafka和传统消息队列的一个最大的区别就是Kafka消息的读写顺序是不一致的，即不能保证全局消息的读写顺序一致性。因为Kafka是分布式的，生产消息不是写到单机上而是写到多个机器上，生产者生产的消息在多个机器上分发，而消费者消费消息时是先消费完一个分区，在消费下一个分区。
	像Kafka这样的消息中间件包括MQ，他们在一个系统的主要作用是上下游解耦，异步提高吞吐量，缓存激增的流量保证系统安全。
	避免生产者模块和消费者模块的直接耦合：在两者之间加入一个消息中间系统，生产者将消息放到中间系统中，消费者从中间系统消费消息，两者都直接和中间系统对接。这样即使消息消费失败也不会影响到消息生产者，消费者也可以更加专注于消息的处理逻辑。
	异步提高吞吐量：消费者生产消息直接放到消息中间件，不会同步等待消息的处理结果，而是继续生产下一个消息。生产者专注于消息的生产，消费者专注于消息的消费，提高了吞吐量。
	缓存激增的流量：消费者和生产者都是有一定的负载的，如果突然过来的请求很大，直接打到消费者的话，会超过消费者的负载，那么直接打到消费者就很可能造成消费者的宕机等故障。所以将突然激增的并发打到消息中间件中，让消费者根据自身的处理能力缓缓处理kafka中积压的消息。避免突然激增的流量直接打到消费者中，或者因为消息产生速度和消费速度不匹配而带来的系统宕机的风险。

	Kafka的优势：
	因为Kafka是天然支持分布式的，所以它的吞吐量非常大，几乎不会因为kafka的吞吐量而限制住两端的吞吐量。
	读写响应快，延迟低。
	数据可靠：kafka中的消息会被持久化到磁盘，并且有数据备份机制防止数据丢失
	容错性：允许系统中有节点失败，不会影响到整个系统的稳定。
	扩展性高：Kafka集群支持热扩展，直接加机器，做好配置后，Kafka内部会自动做好均衡。

	Kafka的优势领域：Kafka比较适合数据量大，高吞吐量，低延迟，读写性能高的场景。比如大数据，日志，绝大部分的统计场景。因为这些场景不需要消息读写的一致性，能接收一定程度的误差，甚至少量的数据丢失。比如大数据，日志，行为数据，绝大部分的统计场景等等。这些场景即使丢失一些数据，或者数据读写顺序的不一致，对最终的统计结果不会造成太大的影响，而且这些场景的数据量有很大，所以Kafka在这些场景非常占优势。
	而像一些事务场景，交易场景，金融计算等功能业务场景下，需要生产消费顺序的强一致的情况下，Kafka就不太适合。

	我们公司：日志采集程序将采集到的日志发送到Kafka集群

17.	说一下Kafka的架构
	Kafka分客户端和服务端，生产者消费者都是客户端Client，服务端是由一台台broker组成的kafka，一台kafka服务器就是一个broker，一个Kafka集群由多个broker组成。
	kafka中的消息数据在逻辑上按照topic主题进行划分的，每个topic又分为若干个分区partitions，每个分区一般又会分为若干个副本，副本的类型有leader副本，follower副本。leader副本主要做读写操作，follower定时从leader副本同步数据，其中的ISR副本也可以参与leader选举。分区partition会尽量的分配到不同的broker机器上，每个分区可以在不同的机器上独立的进行读写操作，不同的消费者可以同时读取不同分区上的数据，所以极大的提高的Kafka的吞吐量。分区的代表是leader副本，leader副本主要处理客户端的读写请求，而follower副本主要做冗余数据，备份数据的作用，所以一个topic下的各个分区的leader副本也会被kafka尽量分不到不同的机器上，这样在多个分区并行处理读写请求时，这些请求能尽量打到不同的broker，实现一定程度的负载均衡。
	还有一种observer副本，只做同步数据，不参与leader副本选举。
	消息偏移量，每个分区中的消息都会被分配一个递增的id。消息偏移量offset记录了当前分区的消费位置，kafak只能保证一个分区的消息的顺序性，不能保证全局消息的顺序性。消息偏移量由一个单独的topic记录，consumer_offsets这个主题来记录。

	分区提高了吞吐行，副本保证了可用性

	kafka是依赖zk的，需要将kafak集群信息，分区信息，副本信息等这些元数据保存到zk上，所以引入了zk作为服务注册。但是在kafka3.x版本，好像就不需要zk了。

18.	ISR和OSR

	ISR：分区的leader副本会维护一个ISR副本列表，列表里面存的是follower副本的broker编号（也包括leader副本的broker编号）。
	ISR副本即同步副本，如果副本的上次同步时间距离当前时间，在配置的副本同步间隔时间之内，那么就是同步副本。只有同步副本才可以参与leader选举。如果某一个ISR副本的上次同步时间超过副本同步时间间隔，那么就会被从ISR列表剔除，称为OSR副本。

19.	Kafka删除topic和增加分区
	kafak删除topic的操作，是先在zk的/admin/delete_topics路径下创建一个与待删除节点同名的节点，用来标记该主题为待删除状态。最后删除操作由Kafka控制器异步完成。先标记，在异步删除。
	已有的topic，kafka只支持增加分区，不支持减少分区。因为减少分区后，分区内的数据要转移到其他分区，设计到数据的合并拼接，新偏移量的维护，不好操作。如果真的需要实现此功能，可以新增一个分区数小的topic，新的数据都生产到新的topic中，等老的topic中的历史数据消费完了后，再去消费新的topic，后面读写都在小的topic里即可。

20.	生产者消息的分配
	如果有key，那么根据key的hash值对分区数取模，结果就是这条消息所放到的分区。
	如果没有key，那么就是分区之间轮询放置。

21.	topic的创建
	指定好主题名，分区数，副本因子后，由kafka服务端controller自行分配分区和副本到broker，kafak服务端会尽量的将分区的leader副本分配到不同的broker上，保证机器负载的均衡。
	手动指定分区和副本的broker分配：replicaAssignments指定分区的每个副本所在的broker，不过kafka也会尽量将leader副本分配到不同的broker上	

22.	消费者消费消息
	首先Kafka客户端消费消息时，是消费者自己拉，不是broker推这样的一个模式。
	在创建一个消费者时，要先指定订阅的主题，还有起始偏移量。起使偏移量有3种策略：
		latest：从最新的消息开始消费，具体就是在该消费者创建后产生的消息才算新的消息，才会被消费。
		earliest：最开始的消息开始消费
		指定的offset：要同时指定分区号，和偏移量，因为每个分区的偏移量时独立的，各自维护的。
		从消费者组内之前记录的偏移量开始消费：单个消费者也有自己的消费者组，下次重新消费时也可以看作是从消费者组内之前记录的偏移量开始消费。
	
	如果新创建的一个消费者（同时也是新的消费者组时），没有指定起始偏移量，那么会从最新生产的消息处开始消费。
	即默认情况下有记录偏移量就从记录的偏移量处开始消费，没有就从最新生产的消息开始消费。
	如果指定的偏移量超过了最大偏移量，那么不会报错，而是自动重置到最大的消息序号后面开始消费。
	消费完一个分区后，再去消费其他分区，所以kafka不能保证全局消息的读写顺序性。

23.	消费者组
	任意一个消费者，都有自己所属的消费者组。如果我们创建消费者没有指定消费者组时，kafka会为其默认创建一个随机的消费者组id。
	消费者组主要是为了提高消费并行度的机制：消费者组下的每个消费者，都可以独立的消费其所属的分区，而且每个分区的偏移量在消费者组内是共享的，消费者重启后可以从消费者组内记录的各个分区的偏移量位置处开始消费。
	消费者组内的每个消费者只能读取自己负责的分区，一个分区不会被分配给消费者组内的多个消费者，即一个分区同时只能被消费者组内的一个消费者消费，但是一个消费者可能被分配多个分区（分区数大于消费者数量时）。
	消费者组是有自动再均衡的机制的，当消费者组首次消费消息，消费者数量发生变化，分区数量发生变化时都会触发消费者组的自动再均衡机制。会取消每个消费者目前负责的分区，然后将分区重新的在消费者之间分配。尽量的保证每个分区都能被均衡的负载，被消费者处理。
	相关的api中，在消费者subscrible定义主题时，有两个回调方法。当发生消费者组再均衡时，消费者取消之前的分区会触发回调方法1，参数就是取消的分区，消费者分配到新的分区后，会触发回调方法2，参数就是新分配的分区。

24.	消费位移的记录
	kafka的消费者，可以记录自己所消费到的消息偏移量，记录的这个偏移量就叫做消费位移。消费位移的一个作用就是当消费者重启后，可以从消费位移处继续往后消费。

	kafka以前的版本消费位移是记录在zk上的，在2.x版本后消费位移由kafka内一个专门的topic记录，这个topic就是__consumer_offsets。kafka消息位移的记录，不是每消费一批消息就提交一批偏移量到__consumer_offsets主题内，而是周期性的提交当前topic各个分区的偏移量到__consumer_offsets主题内。默认情况下是每隔5s提交一次，这个间隔是可任意通过参数配置的。配置的越小提交的越频繁，可以减少消息重复消费的情况。而且在__consumer_offsets主题内记录的偏移量是向后追加，不会更新和删除，所以可能看到相同的偏移量记录。
	
	如果想要看某个消费者组的消费偏移量信息，那么我们要知道它的偏移量信息被记录在__consumer_offsets主题的哪个分区内。默认情况下__consumer_offsets主题是有50个分区的，但是消费者组在__consumer_offsets主题偏移量的记录是有具体运算规律的。根据groupId的哈希值对__consumer_offsets主题分区数取模，就是该消费者组的偏移量记录在__consumer_offsets主题分区位置。

25.	kafka消息生产者的消息应答参数配置ack
	kafka为生产者提供了消息确认机制，可以在构造producer时通过指定ack参数来决定，服务端向生产者发送消息成功写入的条件，生产者根据得到的确认消息来判断消息是否发送成功。
	ack=0：生产者发出消息后不等待服务端的确认，继续发送后续消息。（只管发送）。该模式下运行速度，吞吐量非常大。
	ack=1：生产者发送消息后，要求收到服务端分区的leader副本确保数据接收成功后，发送的确认消息。如果该模式下发送消息时，正在进行正常的leader选举，那么kafka会抛出一个指定的异常给生产者，生产者要能恰当地处理该异常，比如补偿，重试发送消息，确保消息能到新的leader副本中。
	ack=-1/all：生产者发出消息后，要求收到服务端分区的所有ISR副本的确认消息，也包含leader副本本身的应答。生产者会一直重试直到所有同步副本都应答成功后，才会确认该消息发送写入成功。吞吐量低，延迟高，生产端可能会积压大量的待发送的消息。

	一般配置ack=1，能保证吞吐量的同时，兼顾一定的数据准确性。kafak的应用场景一般都是流式计算，行为数据统计能，能接收一定程度的数据误差，不会影响到统计的结果。应该发挥kafka高吞吐量，高响应，读写快的优点。

	ack=-1/all能确保消息的100%发送可靠吗？
	如果只有一个leader副本
	发生了截断：因为follower副本是定期到leader副本同步数据的，那么很多情况下，follower副本的数据offsets是小于leader副本的。如果发生了选举，很可能新选举出来的leader副本的最新数据id小于其他的follower副本，那么其他follower副本就会发生数据截断，保持和leader副本的数据长度一致。这些数据丢失了，但是生产者收到了之前leader的ack确认消息，不会再重发消息，导致该部分消息丢失。

26.	生产者消息发送方式
	发后即忘：生产者只管发送，不关注消息是否正确到达消费者端，一条一条的不断发送。
	同步发送：发送一条消息在这条消息发送成功前（收到ack消息），消息生产者会一直阻塞，直到收到ack消息后才会发送下一条消息。
	异步发送：默认情况下就是异步发送的，也就是一条消息send()后，就会发送另一条消息，不会等待阻塞等待其返回结果。但是在回调参数里面，可以判断发送是否成功。

27.	消费者订阅的几种方式
	在kafka提供的api中，有几种订阅方法。subscribe()和assign()方法。
	subscribe()订阅方法有几种重载方法：
		指定一个主题集合，一次订阅多个主题；
		通过正则指定订阅的主题，后续如果新创建的主题符合该正则，消费者会自动订阅。可以用来动态的增加订阅的主题。
		除了指定主题，还有一个消费者组发生在均衡时的回调
	assign()订阅方法：直接指定要订阅的主题的具体分区。并且搭配seek()方法指定分区的偏移量，从该分区的该偏移量位置开始消费。

	subscribe()和assign()的区别：
	通过subscribe()方法订阅主题时，由kafka来为每个消费者分配分区，而且具有消费者组的自动在均衡功能。当消费者组内的消费者增加或减少时，kafka会自动重新分配分区，保证消费的负载均衡。
	assign()方法订阅分区时不具有消费者自动均衡的功能，消费者只会负责我们手动为其分配的分区。

	
28.	提交偏移量
	kafka中默认的提交消费位移的方式是自动提交，这个是由enable.auto.commit参数控制，默认是true。自动提交不是每消费一条就提交一次，而是定期提交。定期的周期是由auto.commit.interval参数配置，默认是5s。
	在默认情况下，kafka消费者每隔5s会拉取到每个分区中最大的消费位移进行提交，提交到kafka中一个专门记录偏移量的主题__consumer_offsets中。

29.	重复消费和消息丢失	
	重复消费：这种定期异步提交很可能会造成消息的重复消费。比如消费者成功消费了一批数据，然后回去拉取新一批的数据，但是此时每由提交最新的消费偏移量，然后消费者发生故障。那么消费者重启后会从之前提交的消费偏移量开始拉取数据消费，造成消息的重复消息。定期异步提交消费偏移量，造成消费偏移量的更新的不及时，不同步。
	缓解：可以将周期设置的小一点，让定期提交偏移量的动作更频繁，但是也只能缓解重复消费的情况，无法解决。幂等性考虑，即使重复消费了，最终的结果也不会变。
	
	消息丢失：这个情况有一种可能就是我们自己业务处理方面导致的问题。比如我们拉下来一批数据，但是消费者数据拉下来后对我们而言并不意味着这批消息就成功消费，我们后续大概率还要经过处理，数据库操作，缓存操作等等，最终处理完成后这批消息才算消费成功。但是kafka是会定期提交消费偏移量，比如周期5s，我们在拉下来数据5s后，还没有处理完数据，但是该批次消息的偏移量已经被提交了。如果消费者发生了故障，那么消费者重启后会从消费偏移量后拉取新的消息，之前没有处理成功的消息被跳过，相当于消息丢失了。

	解决：手动提交消费者偏移量。
	因为消费偏移量的定期异步提交可能导致消息丢失，重复消费等问题，为了规避消息丢失，重复消费由我们自己来控制消息偏移量的提交。
	
	执行手动提交的前提是需要我们关闭自动提交，enable.auto.commit置为false。 
	手动同步提交commitSync(...)：每消费完一条消息，提交一次偏移量为该消息的偏移量+1，每次都会更新offset为最新的偏移量。提交成功后，才会消费下一条消息。
	手动异步提交commitAsync(...)：我们在处理完一条消息后，通过手动异步提交后，无需等待提交得到结果，就去消费新的消息，一定程度上提升消费的性能。和自动异步提交的区别是由我们来控制提交的时机，在获取到消息后，我们做完一系列的业务动作后，再去异步提交。而不是定期异步提交。

	ack=1或者ack=-1/all，但是只有一个leader副本，导致的消息丢失问题。
	发生了截断：因为follower副本是定期到leader副本同步数据的，那么很多情况下，leader副本的数据offsets是小于leader副本的。如果发生了选举，很可能新选举出来的leader副本的最新数据id小于其他的follower副本，那么其他follower副本就会发生数据截断，保持和leader副本的数据长度一致。这些数据丢失了，但是生产者收到了之前leader的ack确认消息，不会再重发消息，导致该部分消息丢失。


30.	Kafka速度快的原因
	消息的顺序追加，顺序读写比随机读写快很多。
	页缓存技术：数据交给操作系统的页缓存，并不是真正刷入磁盘，而是定期刷入磁盘
	零拷贝技术：...

31.	kafka的事务
	保证拉取消息，消费消息，结果写入kafka，提交消费位移这一系列步骤具有原子性。
	要提供一个位移事务id并且开启生产者的幂等性，然后可以通过模板代码，初始化事务，开启事务，提交事务，回滚等。

32.	kafka的幂等性
	kafka的幂等性主要是指生产者多次发送同一条消息的幂等性，一个生产者如果多次重试发送消息后，服务器中的结果还是只有这一条，那就具备幂等性。
	主要为了解决：下游已经接收成功了并返回成功消息，但是上游在收到接收成功信号前，再次重试动作。保证kafka中的该消息只有一条。
	开启幂等性是的ack参数要为-1
	大致原理：生产者为每个分区维护一个序列号producer_id，每成功发送一条消息时该id+1。发送消息时会将该序列号+1发送给broker。broker也会为每个分区维护一个producer_id，当收到消息时会对比服务端的id+1是否等于收到id，如果等于那么就正常，如果id+1大于收到的id，那么就是重复发送的消息直接丢失。如果id+1小于收到的id，那么就说明丢失了数据，报错。
	

33.	RabbitMQ介绍一下
	RabbitMQ的工作模式大概是这样的：有一个生产者，生产者会将消息发到交换机，交换机会再将消息根据具体的路由规则路由的不同的队列中。然后消费者根据监听或者订阅的主题，到对应的队列中消费消息。
	RabbitMQ是Erlang编写的，是一个轻量级的消息队列，支持消息的顺序读写。
	RabbitMQ的一些缺点：
		对消息堆积的支持不好，当大量消息堆积时，RabbitMQ处理起来性能较差
		整体吞吐量性能较小：适合中小型的系统
		编程语言是Erlang，生态较小，扩展和二次开发较难，遇到疑难杂成处理起来较难。

34.	RabbitMQ的工作模式
	简单工作队列模式：不需要创建交换机，直接用默认的交换机（交换机类型为Direct），路由键是队列名称。如果多个消费者监听同一个队列，那么消费者轮询消费队列中的消息。
	pub/sub模式：需要创建一个交换机，并且交换机的类型是Fanout扇形，然后为交换机绑定要广播的队列，路由键设置""空字符串，表示交换机会将消息发送到所有与之绑定的队列。之后在消费者客户端中监听指定的队列即可消费。
	Routing路由模式：也要创建交换机，并且交换机的类型是Direct。在将队列和交换机绑定时，指定具体的路由Key。每次发送消息时，也都要指定RoutingKey，后续只有满足RoutingKey的队列才会收到交换机转发过来的消息。
	Topic主题通配模式：创建一个Topic类型的交换机，再将队列和交换机绑定时，可以通过通配符来指定Routingkey。后续如果发送的消息的RoutingKey满足队列交换机绑定时的RoutingKey，就会发到指定的队列。消费者监听对应的队列即可消费到消息。

35.	RabbitMQ保证消息的可靠投递
	RabbitMQ投递消息的路径大致为：生产者，broker服务端，交换机，队列，消费者。
	RabbitMQ会通过消费者和生产者，还有持久化机制共同保证消息的可靠投递。

	生产者可以通过confirm确认模式，确保消息发送到Exchange交换机，为rabbitTemplate设置一个setConfirmCallback，其中的confirm()方法的ack参数如果是true就说明exchange交换机接收消息成功了。
	生产者可以通过return机制确保消息成功发送从交换机路由队列中，同样也是为rabbitTemplate设置一个setReturnCallback，其中的returnedMessage()里面可以判断消息有没有路由成功。（如果队列满了，或者消息死亡了，虽然该消息不会被路由到交换机，可是不会触发该回调）

	消费者可以通过ack的确认机制，来设置消费端收到消息后的应答。有自动确认acknowledge="none"和手动确认acknowledge="manual"。自动确认是当消息一旦被消费者接收到，就自动确认收到。手动确认要开启对应的配置，在我们业务处理成功后，可以通过api，channel.basicAck方法确认消息成功消费，否则拒绝确认，再将其放入队列重新消费
	
	还有持久化机制，集群也能在一定程度上保证消息的可靠性投递。

36.	死信交换机
	死消息：比如队列长度达到限制，再次进来的消息会被直接拒绝就是死消息；或者消息的TTL过期；或者被拒绝ack的消息，并且不将其放入原队列。
	当消息成为死消息后会被重新发送的一个交换机，这个交换机就是死信交换机DLX。我们可以创建一个队列和死信交互机绑定，后续死信消息会被死信交换机路由到死信队列。
	
	死信交换机实现延迟队列的功能：在指定正常队列和正常交换机时，可以通过参数指定当消息成为死消息时发送到的死信交换机的名称和对应的RoutingKey，然后我们在专门创建一个队列，将其和刚才指定的死信交换机绑定，并指定匹配的RoutingKey。后续当消息在TTL过期后会发送到死信交换机，然后死信交换机在路由到死信队列。我们监听死信队列，在TTL后就能消费到消息，实现了延迟队列的功能。

37.	Spring的一些扩展点
	@PostConstruct ：是针对单个Bean的一个扩展，标注的方法会在这个Bean实例化后，初始化过程中的执行的，具体是在构造函数调用后，依赖注入完成后执行的。
	InitializingBean接口的afterPropertiesSet()方法：也是针对单个Bean的扩展点，在Bean生命周期的初始化阶段执行，@PostConstruct后执行
	SmartInitializingSingleton接口的afterSingletonsInstantiated方法：是针对整个SpringBoot应用的扩展点，在Spring容器中所有的单例Bean实例化和初始化完成后执行的，提供了一个扩展全局的初始化工作。
	BeanPostProcessor.postProcessAfterInitialization()：也是针对单个Bean的扩展点，初始化后后置处理器，Spring会在所有Bean初始化后，拿到所有的BeanPostProcessor接口，执行其中的postProcessAfterInitialization方法。经过该步骤后，得到真正完整的Bean。
	（初始化后扩展点：先执行全局的扩展，在执行单个Bean的扩展）
	WebServerInitializedEvent：Spring应用程序启动完成后会发送一个事件，如果我们要在Spring容器初始化完成后做一些事情，可以监听这个事件，然后在事件的回调里做我们要扩展点逻辑。
	大致从上到下的一个执行顺序

38.	怎么拿到Spring容器：ApplicationContext可以发布事件
	直接注入ApplicationContext 属性
	Spring提供了很多Aware接口，Aware接口就是用来回传一些公共资源和对象的。实现ApplicationContextAware 接口，获取ApplicationContext容器对象。

39.	我想让有些类不加载怎么做
	主要就是不扫描，比如用@ComponentScan注解中的excludeFilters属性，指定我们扫描时要排除的类

40.	MQ控制顺序消费消息
	因为队列这种数据结构天然就是先进先出的，能保证消息的读写顺序是一致的。所以想要控制顺序消费消息，我们应该让每个队列对应一个消费者监听消费。如果有多个消费者监听同一个队列，那么多个消费者会竞争消费队列中的消息，导致消息消费的乱序。
	
	当然也可以考虑为消息加上一个递增的id，我们在消费者端的代码里手动排序控制。

	Kafka虽然全局不能保证消息的读写一致性，但是能保证单个分区内消息的顺序性，所以可以考虑新建一个只有一个分区的topic。只对一个分区进行生产消费就能保证消费的顺序。

41.	starter是什么，怎么自定义starter。
	SpringBoot将开发工作中可能遇到的各种各样的依赖场景抽象成了一个个的starter。就比如之前的Spring项目中，如果需要使用tomcat，就需要引入tomcat-core，tomcat-api等等若干个依赖。但是在SpringBoot中只需要引入一个tomcat-starter依赖即可，这个starter里面已经包含了使用tomcat需要的必要依赖。所以有了starter非常便于我们进行依赖管理，可以很快速的进行某个场景需要的依赖引入。用到什么场景，引入对应的starter依赖即可。
	而且SpringBoot有一个版本仲裁中心，帮我们做好了starter的版本选择和适配，避免了棘手版本冲突问题。
	所以starter本质上也是一个maven依赖，只不过starter里面还包含了一系列的相关依赖，帮我们快速配置相关场景。

	自定义一个starter：通常创建一个以starter结尾的maven项目，这个项目中可以定义该starter的功能，比如编写自动配置类初始化starter。然后通过maven打包成一个可控其他项目引入的JAR包，在其他SpringBoot项目中，就可以将这个starter添加到依赖列表中。
	
	版本仲裁中心：spring-boot的父依赖是spring-boot-parent，spring-boot-parent的父依赖是spring-boot-dependenciess，版本仲裁中心的 propeties标签里面定义了很多的依赖版本，所以如果我们用这些依赖就不需要指定版本号，版本仲裁中心帮我们管理了各个依赖的版本避免了版本冲突。

42.	SpringBoot自动配置原理
	从SpringBoot应用的启动类来说，SpringBoot的启动类上都是有@SpringBootApplication这个注解的，这个注解又包含了3个比较重要的子注解。
	@SpringBootConfiguration，其实就是@Configuration注解。
	@ComponentScan注解
	@EnableAutoConfiguration注解。

	其中@SpringBootConfiguration注解定义了启动类是也一个配置类，Spring会在启动时对其进行扫描，生成相应的Bean。那么在扫描解析该配置类的过程中，也会解析其他的两个注解@ComponentScan和@EnableAutoConfiguration。
	
	那么解析@ComponentScan注解时，Spring容器就会扫描当前包及其子包下面的所以类，将符合扫描器逻辑的类注册成Spring的Bean。

	然后解析@EnableAutoConfiguration注解，是一个很关键的注解。SpringBoot主要就是通过这个注解开启自动装配的功能。这个注解也是一个复合注解，其中通过@Import注解引入了一个配置类AutoConfigurationImportSelector，这个配置类实现了DeferredImportSelector接口，其中实现的selectImports()方法回去解析META-INF/spring.factories文件，得到重多自动配置类的类名。这些自动配置类不一定都会扫描注册，SpringBoot会判断@EnableAutoConfiguration中的exclude属性，剔除不需要扫描注册的自动配置类。而且很多自动配置类是和@Conditional注解结合使用的，比如@ConditionalOnMissingBean，@ConditionalOnClass等等，SpringBoot会结合这些条件注解进一步判断是否生成对应的自动配置Bean。
	而且还有一点比较关键，就是@EnableAutoConfiguration注解通过@Import注解引入AutoConfigurationImportSelector这个配置类，它实现的是DeferredImportSelector这个接口。这个接口中的selectImports()方法会在处理完我们当前目录下的配置类后在调用selectImports()方法，处理放啊返回的配置类。如果解析注册配置了的顺序不能满足这个顺序的话，@ConditionalOnMissingBean这种注解就可能失效。比如我们不想要SpringBoot实现写好的自动配置类，我们想要自己定义一个配置类，并且覆盖SpringBoot提供的自动配置类。SpringBoot肯定会事先提供好接口供我们来实现扩展自己的配置类，然后SpringBoot在自己的自动配置类上加上@ConditionalMissingBean来控制如果没有我们自己定义的配置Bean，自动配置类才会生效。但是如果是先扫描SpringBoot的自动配置类，此时还没有扫描生成项目目录下我们自己定义的配置Bean，那么@ConditionalOnMissingBean也会生效，那么我们的自定义的配置类就无法覆盖SpringBoot提供的自动配置类。所以实现的是DeferredImportSelector接口是很有必要的。

43.	创建注册Spring Bean的方式
	一般项目中各个代码层之间可以通过：@Service，@Controller，@Component等注解指定当前类是一个SpringBean
	最推荐的是@Configuration和@Bean注入配置类
	还有@Import引入一个配置类
	@ImportResource指定配置文件，配置文件中写很多Bean的定义
	还有编程式的注册Bean，拿到容器，通过注册Bean定义，创建Bean实例。

44.	SpringBean的扫描过程
	Spring会在启动的时候扫描包路径下的所有class文件，生成对应的文件对象。然后根据文件对象解析出来class文件的元数据信息。开始对这些class进行筛选，比如该class是否是excludeFilter指定的，如果是就排除它；比如该class是否满足@Conditional条件注解中指定的条件；比如是否是抽象类或者接口，如果是也会将其排除；如果满足就继续后续的判断。最后经过筛选后得到的class会生成一个个的BeanDefinition，然后为BeanDefinition生成对应的beanName，生成beanName时会解析@Component，@Service等注解是否指定了beanName，如果没有就根据默认逻辑生成，比如类名首字母小写。BeanDefinition对象里面有些属性就表明了这个bean对象的一些定义，比如是不是单例bean，是不是懒加载，有没有依赖其他的Bean等。所以会解析类上有没有加@Lazy，@DependOn，@Scope，@Primary等注解，解析后赋值到BeanDefinition中的对象属性上，即BeanDefinition的属性初始化。然后根据beanName判断该BeanDefinition是否已经在容器中注册，如果没有的话将BeanDefinition注册到容器中，到这里扫描就差不多结束了。

45.	SpringBean的生命周期
	首先是扫描加载class文件，生成对应的BeanDefinition注册到容器中。
	BeanDefinition生成好后，意味着扫描逻辑结束了，那么就可以开始实例化了。
	实例化前：在这一阶段Spring也提供了对应的扩展点，实现该接口可以在Bean实例化前做一些自定义扩展。
	实例化：这里就会调用构造方法实例化对象，所以会有推断构造方法这一过程。	
	实例化后：在这里Spring也提供了一个扩展点，实现对应的接口，能在Bean实例化后执行一些逻辑。
	
	然后进行属性注入的处理：比如@Autowired，@Resource，@Value等注解，进行属性注入
	初始化前：为进行了属性注入的Bean对象进行处理，在这一步会执行@PostConstruct注解的方法。Spring也提供了扩展的接口，我们可以实现该接口，进行定制化处理。
	执行各个Aware接口的回调：比如BeanNeamAware回传beanAware给bean对象，BeanFactoryAware回传beanFactory给Bean对象。ApplicationContextAware接口获取Spring容器对象。
	初始化：查看当前Bean是否实现了InitializingBean接口，如果实现了就调用其中的afterPropertiesSet()方法。
	初始化后：这里就是Bean创建的最后一个步骤了，Spring也提供了相应的扩展点。比如BeanPostProcessor.postProcessAfterInitialization()方法。Spring容器会有一个List存储着所有的BeanPostProcessor，然后将其依次遍历执行其中的postProcess方法。Spring中的AOP就是在初始化后基于BeanPostProcess实现的，初始化后返回的对象才是最终的Bean对象。
	

46.	Spring的IOC，DI	
	SpringIOC就是控制反转的意思，主要就是将对象的控制管理由我们自己管理交给Spring来管理。比如以前我们需要自己创建对象，为对象进行属性赋值，管理对象间的依赖关系。现在将对象的创建，加工，初始化，销毁等一系列生命周期过程都交给Spring来管理。Spring会在启动的时候自动创建我们通过注解指定的对象，注册放到IOC容器中。
	而且再后续如果有其他对象需要用到该对象，就会从IOC容器中拿到该对象，将其注入需要的地方。这一点就是DI依赖注入，这样对象间的依赖关系也不需要我们来维护了，也是由Spring来帮我们管理。

	Spring通过IOC和DI依赖注入，帮我们统一管理对象，维护对象间的依赖关系。这样开发人员就不需要耗费过多的精力在对象管理，依赖管理方面，而且也在一定程度上将代码进行了解耦。对象间的依赖关系，通过一个注解就可以注入进来，各个代码层对象直接的依赖关系，比如业务层和持久层直接的依赖关系，不需要我们通过new对象来进行依赖注入，直接交给Spring来进行管理和注入。代码各个层次之间更加分明，耦合度降低。

47.	SpringAOP
	AOP是一种编程思想，主要就是在不修改原逻辑的基础上，将其作为切点，将需要新增的逻辑定义成一个通知，配置通知和切点的匹配绑定关系后，来增强原逻辑的功能。比如我们要为a()方法增加一些功能，但是这个功能和业务关系不大，而且很多方法都要新增这个功能。我们就可以通过AOP切面的编程思想，将其作为切点，把新增的逻辑作为通知Advice配置在这些方法上面。这样我们既不需要修改源逻辑代码，也避免了写很多重复的逻辑。
	AOP帮我们解决抽取重复公共代码，将公共代码抽取出来作为通知，单独管理配置，也更利于后续的维护。后续发生变动，只需要改通知即可。
	
	底层主要是采用动态代理的技术，为要增强的对象生成代理对象，后续原方法的执行会被拦截，进入代理对象内，然后再原方法的前后执行切面逻辑，对target目标对象进行增强装饰。

	SpringAOP的实现逻辑主要是在Bean的初始化后阶段，通过BeanPostProcessor这个扩展机制来实现的。
	@EnableAspectJAutoProxy这个注解开启了SpringAOP，这个注解内又通过@Import注解注册了一个BeanPostProcessor，在每个Bean的初始化后阶段都会执行这个BeanPostProcessor的逻辑。
	这个BeanPostProcessor会判断当前这个Bean是否需要进行AOP：大致的判断逻辑，是拿到我们配置的所有的Advisor然后一次遍历所有的Advisor切面，判断当前的bean对象是否和某个Advisor匹配，如果匹配就说明当前Bean配置了切面，需要进行AOP。
	然后开始进行AOP，为当前Bean对象创建代理对象，同时再次遍历所有的Advisor，将匹配该Bean的所有Advisor加到代理逻辑中。最后得到最终的AOP切面代理对象。
	后续代理对象执行某个方法时，就会执行加进来的所有匹配的Advisor，执行切面逻辑。

	一般使用起来是通过@Pointcut加在方法上面，定义切入点表达式，定义方法和通知切面逻辑的关联关系。然后在通过@After，@Before等来指定通知的类型。

48.	Spring的事务传播机制
	PROPAGATION_NEVER：不用事务，如果外层有事务，抛异常。
	PROPAGATION_REQUIRED：默认的事务传播机制，如果外层有事务，就用外层的事务。而且两个方法会使用同一个数据库连接对象，保证受同一个事务控制。
	PROPAGATION_REQUIRES_NEW：即使外层有事务，也会新建一个数据库连接对象，使用新的事务。

49.	Spring的事务
	如果当前类或者方法上加了@Transactional注解的话，方法在执行时会走到AOP代理对象的Spring事务逻辑中。利用配置的事务管理器新建一个数据库连接，将这个数据库连接储存到当前线程的ThreadLocal中，并且设置数据库连接的auto commit为false。如果方法内调用了其他的方法，并且也开启了Spring事务，并且传播机制是要融合到外层事务的话，那么就会到当前线程的threadlocal获取刚才创建的数据库连接，保证这若干次操作都在同一个数据库连接范围。这样就保证了两个方法的数据库操作在一个事务内，然后执行业务，正常就提交，异常就回滚，然后再销毁threadlocal中的coon数据库连接。

50.	Spring是怎么解决循环依赖的
	循环依赖我个人的理解是这样的，举个简单的例子。A对象中有个属性是B，B对象中有个属性是A，这样就构成了一个简单的循环依赖的关系。但是其实单纯的从Java代码来看的话，循环依赖不是个问题，这种对象间的依赖非常多，也很正常，不会影响对象的正常创建（会赋值初始默认值）。但是在Spring中，循环依赖就成了一个问题了。因为Spring它要创建的不是一个简单的Java对象，而是一个Spring Bean。大多数情况下这个Bean是一个单例Bean，而且在创建的时候就要将其中的属性进行赋值，即完成依赖注入。如果在进行依赖注入的时候，出现了循环依赖，那么就会出现问题，A类型的Bean创建时需要注入B对象，发现B类型的Bean还没有创建好，那么通知B创建Bean，B创建的时候又发现需要A。B在等待去通知A，最后两者都互相等待，无法正常创建，有点死锁的感觉，互相持有不让渡出来。所以循环依赖在Spring里面是一个问题。
	Spring是怎么解决循环以来的呢？
	Spring解决循环依赖主要通过引入三级缓存来解决。
	假如A类在创建Beaen，实例化一个A类的对象后，会先在3级缓存中缓存一个key-value，key是beanName，value是ObjectFactory这一个函数式接口，其实就是一段逻辑。如果bean需要进行AOP的，这个接口主要是为了生成AOP代理对象的，这也是为什么要引入三级缓存的原因。同时向一个Set存入A的beanName，表示A正在创建。
	然后开始为A对象进行属性填充，依赖注入，发现需要注入B对象。先从一级缓存，单例池中查找看看B有没有已经创建好的Bean，如果没有。再查看刚才说的那个Set，看看B是否正在创建，也没有，说明B还没开始创建，那么此时A会先暂停，转而开始创建B类的Bean对象。

	开始创建B对象，实例化好一个B对象后，也先放到三级缓存，key是beanName，value是objectFactory。同时向一个Set存入B的beanName，表示B正在创建。
	开始为B填充属性，依赖注入，发现需要注入A对象，也是先查看一级缓存，发现A还没创建好。然后查询Set，在Set中发现了A的beanNaem，此时B创建的过程中发现A也正在创建，说明两者发生了循环依赖。出现了循环依赖后，B会继续判断二级缓存，发现也没有A的Bean，然后再去三级缓存中找到了A缓存的数据。此时后执行ObjectFactory接口对应的逻辑，这段逻辑会判断A对象是否需要进行AOP，如果需要Spring就会生成代理对象当道二级缓存中，不需要就生成原始对象放到二级缓存中。
	移除三级缓存中对应的A的数据，还有一个Map记录了A已经发生过AOP了。
	此时就可以将A对象注入到B中了。最后将创建好的Bean对象放到一级缓存中。

	A继续后续Bean的生命周期，假如A要进行AOP，那么在初始化后节点，会判断那个Map中是否又A的beanName，如果有就说明A已经完成了AOP了，那么就不需要再进行AOP了。直接从二级缓存中拿到AOP代理对象放到一级缓存中作为最终的A类型的Bean。

	所以主要是三级缓存打破了循环依赖，而且它还兼容了AOP的情况，他创建了半成品的对象或者代理对象，然后放到二级缓存。
	二级缓存缓存下来三级缓存生成的半成品的Bean对象或者代理对象，后续还有依赖情况的，可以直接从二级缓存中拿，保证注入的是同一个单例对象。


51.	Mybatis的一级缓存和二级缓存
	Mybatis的一级缓存是SqlSession层面的缓存，Mybatis在开启一个数据库会话时，会创建一个新的SqlSession对象，SqlSession内部会有一块区域作为Mybatis的一级缓存，缓存每次的查询结果。我们在一次数据库的会话中，如果执行了两次相同的查询操作，那么第二次就会直接从一级缓存中获取第一次查询的结果。如果发生了修改等操作，那么一级缓存会被清空。Mybatis的一级缓存是默认开启的。
	一级缓存可能会破坏数据库的隔离级别，比如两次相同的查询之间，有其他的数据库会话做了修改操作，而且我们的隔离级别是读未提交，那么第二次查询的结果还是修改之前的结果，破坏了读未提交隔离级别。
	Spring和Mybatis一起使用时，可能破坏Mybatis的一级缓存。通过@Transactional注解能保证多次的数据库操作都是一个数据库连接，即都在一个数据库会话SqlSession范围内，那么多次相同的查询就都在一个SqlSession范围内，能保证Mybatis一级缓存起作用。

	Mybatis的二级缓存是SqlSessionFactory对象的缓存，指的是由Sql会话工厂创建的SqlSession对象共享这个缓存。二级缓存的作用域是mapper文件的同一个namespace。SqlSessionFactory层面的二级缓存是默认不开启的，二级缓存的开启需要额外的配置。
	二级缓存用的不多，会导致一些问题。比如开启二级缓存后，MapperA和MapperB是不同的namespace，他们的二级缓存是独立的。如果MapperA执行了查询后将结果缓存到二级缓存，MapperB更新了这个数据，但是因为不在同一个二级缓存，所以MapperA的二级缓存不会刷新。后续MapperA在命中该查询时从二级缓存中获取的是旧数据。
	
	开启二级缓存后：先二级缓存--->一级缓存--->数据库。

52.	SpringMvc的大致流程
	用户发送到服务的所有请求会被DispatcherServlet拦截到，因为DispatcherServlet配置的拦截路径是/*
	DispatcherServlet收到请求后，根据url找到一个处理映射器HandlerMapping。
	通过处理器映射器，生成处理器执行链HandlerExecuteChain，根据处理器执行链得到对应的处理器适配器HandlerAdapter。处理器适配器可以做一些参数封装，数据格式转换，数据验证等操作。
	执行处理器适配器的handler()方法来调用处理器的业务逻辑。
	Handler会返回执行结果的数据和视图返回给DispatcherServlet。
	DispatcherServlet渲染视图和数据等等。

53.	count(*), count(1), count(id), count('字段')区别和效率
	从效率方面来看：count(*) = count(1) > count(id) > count('字段')
	count()是一个聚合函数，判断参数内不为NULL的记录有多少条。
	在通过count()函数统计有多少条记录时，MySQL的Server层会维护一个名叫count的变量，Server层会循环向InnoDB读取一条记录，如果count函数指定的参数不为NULL，那么就会将变量count加1。最后将所有数据循环一遍后，得到最后的count返回给客户端。
	count(id)：就是判断所有记录中，id不为NULL的记录有多少条。如果表中只有主键索引的话，InnoDB会循环读取聚簇索引记录，判断其中的id值是否为NULL，不为NULL，count+1。如果有二级索引的话，会循环读取二级索引记录，判断二级索引记录中的id列是否为NULl，不为NULL，count+1。为什么优先循环二级索引，因为二级索引记录的叶子节点存储的是主键和索引列，聚簇索引存储的是整个记录，所以同一条记录，二级索引记录要小，那么读取判断时的IO消耗也会更小。
	count(1)：就是判断所有记录中，1不为NULl的有多少条，那么显然1本来就不是NULL，所以等价于统计表中有多少条记录。count(1)相比于count(id)，不会去读取记录中的id值，循环到一条记录就count+1即可。所以count(1)的效率要比count(id)高。而且如果有二级索引的话，也是优先循环二级索引。
	count(*)：MySQL会把count(*)转换成count(0)，原理等价于count(1)，所以count(*)和count(1)效率没有差异。
	count('字段')：判断所有记录，该字段不为NULL的有多少条。首先语义上就不是统计有多少条记录，而且该语句的执行计划是扫描全表，效率很差。

54.	事务的特性
	事务是由MySQL的引擎来实现的，MySQL默认的InnoDB引擎他就是支持事务的。不过并不是所有引擎都能支持事务，弄如MyISAM引擎就不支持事务。
	原子性：让多个数据库操作要么同时成功，要么同时失败。不会出现部分成功的情况。
	一致性：经过事务内的一组操作之后，数据最终的结果是正确的。
	隔离性：数据库允许多个并发事务对数据进行读写和修改，隔离性能防止并发事务由于交叉执行导致的数据不一致的情况。隔离性也就是并发事务之间不会互相干扰，每个事务都有独立完整的空间，对其他并发事务是隔离的。
	持久性：事务处理结束后，对数据的修改是永久生效的。

	持久性：通过redo log重做日志来保证的
	原子性：通过undo log回滚日志来保证的
	隔离性：是通过MVCC多版本并发控制或者锁机制来保证的。
	一致性：则是持久性+原子性+隔离性来保证的。

55.	事务的隔离级别
	因为数据库是允许并发事务的，所以在多个事务在操作同一个数据时，就可能会造成一些问题。
	脏读：事务A和事务B同时操作一份数据，事务A读到了事务B还没提交数据。因为事务B还未提交，后续事务B时可能发生回滚的，所以事务A读到的就是错误的数据。
	不可重复读：事务A在多次读取一条数据时，出现前后两次结果不一样的情况。因为在两次读取之间，可能有事务B修改了该数据，并且提交了。那么就会造成事务读取同一条数据，结果前后两次不一致的情况。即不可重复读。
	幻读：事务A在多次查询符合谋和查询条件的记录数量时，出现了前后两次查询统计结果不一样的情况，这就意味着出现了幻读。因为可能在这期间有其他并行事务新增了或删除符合条件的数据。

	因为并发事务可能会导致这些问题，SQL标准引入隔离级别来规避这些问题。具体的事务隔离级别有如下：
	读未提交：就是不做什么措施，一个事务还未提交的修改，也能被其他事务读到。
	读已提交：每个事务只能读到其他事务已提交的数据
	可重复读：一个事务执行期间所能读到的数据，和它在事务开启时读到的数据保持一致。这也是MySQL默认的事务隔离级别。
	串行化：为记录加上读写锁，在多个事务对这个记录进行读写操作时，每个事务串行化访问该记录。

	这四种隔离级别：
	读未提交没有解决任何一个上面并发事务引起的问题。
	读已提交能解决脏读的问题。
	可重复读解决了脏读和不可重复读的问题
	串行化解决了脏读，不可重复读，幻读的问题。
	这四种隔离级别的隔离水平依次递增，但是效率依次递减，尤其是串行化效率很低。

	这四种隔离级别的实现方式：
	读未提交：因为可以读到未提交事务修改的数据，所以直接都最新的数据就好了。
	串行化：通过加读写锁来避免对同一个数据的并行操作。
	读已提交和可重复读：他们是通过MVCC结合Read View快照来实现的。两者大致区别在于创建Read View的时机不同。读已提交会在每个语句执行前都重新生成一个最新的Read View，而可重复读只在事务启动时生成一个Read View，整个事务期间都只用这一份Read View。

56.	MVCC
	MVCC也叫做多版本并发控制，主要是用来控制并发事务访问同一条记录的行为。MVCC主要是通过Read View来控制并发事务访问同一条记录的。
	Read View类似一种快照，会记录下当前时刻数据库中的事务的一些情况。Read View其中有比较重要的几个字段：
	活跃着的事务id列表
	活跃事务id的最小值
	下一个要分配的事务id
	当前事务的id 
	
	然后我们还要知道每条记录中还会有一些隐藏列，其中就有最后操作该条记录的事务id，undo日志指针。

	假如当前数据库的隔离级别是可重复读，那么事务A在启动时会生成一个Read View，Read View记录了当前活跃的还未提交的事务id列表，活跃事务id的最小值，下一个要分配的事务id，当前事务id。那么事务A在操作记录时，会先根据Read View中记录的活跃事务id的字段判断当前这条记录的事务id是不是活跃事务。如果不是那就说明在事务A创建之前，这条数据的事务已经提交了，所以直接读取。如果这条记录的id是在活跃事务id列表内，说明当前操作该数据事务还未提交，这个事务实在A事务后开启的，按照可重复读隔离级别是不能读取的。那么会沿着该记录的undo日志指针向下找旧本版的记录，直到找到第一条记录的事务id小于事务A中记录的活跃事务id的最小值的记录，进行读取。可重复读是只在事务开启时创建一次Read View，后续事务执行期间一直用同一份Read View。
	假如当前事务的隔离级别是读已提交，那么事务会在每次进行数据库操作时都创建一份最新的Read View，其他过程和可重复读是一致的。

57.	MySQL的索引
	MySQL默认的存储引擎是InnoDB，存储引擎主要的工作就是如何存储数据，如何为存储的数据建立索引，如何更新，查询数据等技术等。
	索引就是帮助存储引擎快速获取数据的一种结构，类似目录，能够根据索引快速定位到要访问的数据。MySQL这的索引也是一种组织数据记录的格式，记录会按照索引的格式进行组织排序等。
	MySQL中的索引可以分为主键索引和二级索引。
	首先MySQL中定义的表一般都会有主键，如果没有主键，MySQL会查找表中是否有不为NULL的唯一列，如果有的话将其作为主键，如果仍然没有那么会生成一个自增ROW_ID隐藏列作为该表的主键。MySQL会根据主键生成一个主键索引，也叫做聚簇索引。聚簇索引的底层实现是B+树，它的大致结构是这样的：
	聚簇索引分为叶子节点和非叶子节点，但是无论是叶子节点还是非叶子节点其实都一个个的数据页，每个数据页的默认大小是16k。但是叶子节点的数据页中存储的是一个个的完整的用户记录，每个用户记录按照id排序，并且在页内组成了一个链表，而所有的叶子节点也是按照id排好序的，然后组成了双向链表，双向链表就既可以从前查找，也可以从后查找。非叶子节点的数据页中存储的是一个个目录项记录，目录项记录主要就是存储主键id和页号。聚簇索引的工作方式时，拿着主键id，从上往下判断该id所在的目录项记录，然后根据目录项记录找到该记录所在的数据页，因为数据页内的记录是按照id排好序的，那么通过二分查找就能很快找到定位到具体的那条记录。
	二级索引底层的底层也是使用的B+树，和主键索引最大的区别就是，二级索引的叶子节点中的记录不是完整的数据记录，而是索引列+主键id，二级索引的非叶子节点中记录是索引列+页号。所以在使用二级索引定位数据时，会先根据索引列值定位到非叶子节点，然后根据非叶子节点中的页号定位到二级索引的叶子节点，拿到该条记录的主键id，然后再到聚簇索引进行一次回表查找操作，找到真正的记录。而且二级索引中叶子节点数据的排序规则是：比如按照c1，c2建立的二级索引，那么二级索引中记录的排序规则是，先按照c1排序，c1相同的在按照c2排序，如果c2再相同按照id排序，所以所有的二级索引都可以认为是索引列+主键的联合索引。

	索引的维护更新成文也很好，本省也很占内存，每次删除，新增操作都会涉及到索引的维护，新纪录的重新排序，开销较大。

58.	为什么选择B+树作为索引的数据结构
	B+树只在叶子节点存储数据，非叶子节点只存储目录项记录，所以整体而言能节省不少空间。
	B+树相较于二叉树而言，每个节点可以有很多孩子节点，那么就可以在很低的层级下存储非常多的数据。比如每个节点，也就是每个数据页能存100个记录，那么两层就能存10000个数据页，10000个数据页就是1000000万条记录。如果是三层就是1000000个数据页，就是100000000条记录。那么更小的层级，也就意味再进行查询时，需要遍历的层级更小，需要进行的IO次数更少，效率很高。
	B+树的叶子节点是按顺序排序的，而且是一个双向链表，节点内的数据也是按照id顺序排列单链表。因为是按照顺序排列的，所以无论是单个查询，还是范围查询效率都很高，使用二分查找就能很快地定位到数据了。

59.	索引失效的一些情况
	索引是否可以命中的一个判断依据，sql的查询条件是否符合索引的排序顺序。如果符合，那么就可以按照索引记录的排序顺序根据二分查找快读的定位到要查找的记录。
	比如有一个c1，c2，c3的联合索引，如果我们的查询条件是where c1= '' and c2 = '' and c3 = ''，那么就能命中这个联合索引。因为这个联合索引的排序规则就是先按照c1排序，c1相等的话再按照c2排序，c2再相等的话按照c3排序。
	查询条件部分满足这个联合索引排序顺序，也可以使用索引，比如where c1 = '' 或者 where c1 = '' and c2 = '' 或者where c1 = '' and c2 > ''。也能满足先按照c1排序，c1相等的话再按照c2排序。
	如果不满足c1，c2，c3这样的排序的话，就不会命中索引，比如where c2 = ''，或者 where c2 = '' and c3 = ''。无法根据c1，c2，c3这个联合索引进行查找。

	所以像like条件，要使用like 'xxx%'即like的字符串后模糊匹配，否则也会索引失效。
	排序时ASC和DESC混用，也会造成索引失效，不能使用索引对数据进行排序
	排序语句不符合索引的排序规则：比如c1，c2联合索引，但是排序是order by c2, c1
	在查询语句中索引列不是单独使用，比如搭配函数使用，或者在运算表达式里面
	group by语句的分组规则和索引的排序规则不一致。
	
	有时候可以命中二级索引，但是命中二级索引得到的数据量很大，后续还要在进行大量的回表操作，那么MySQL优化器可能就不走二级索引了，直接进行全表扫描。引起上述问题的一个原因是我们的查询条件粒度比较大大，或者二级索引的区分度不高。

60.	SQL一些优化点
	索引覆盖：查询语句时，如果能够直接索引覆盖，那么就可以直接从二级索引返回结果，避免回表操作。
	不为区分度小的列建索引：如果一个列的区分度太小，即重复值很多，那么就会导致用该二级索引时，筛选后的记录很多，回表操作也很多，MySQL最后肯定会直接走全表，不走索引。
	建立联合索引时：尽量区分度高的列放在前面。
	如果某列值很大，那么可以考虑为该列的前缀建立索引，避免索引结构太大
	尽量为频繁用到的语句中的where条件，order by条件，group by 条件建立索引。
	如果建立的联合索引，要避免建立一些冗余的索引。比如a，b，c，那么就不需要建立a或者a，b索引了。

61.	策略模式
	用的多的是策略模式，当时有个需求要同步第三方的流水，流水类型大概有银联流水，移动支付流水，同步方式又分为手动同步，自动同步。当时写这个需求的时候，一开始直接的想法就是每种流水的同步类型对应一个接口，感觉这样写那么多接口没意义，然后就都放到一个接口里面，根据参数区分不同类型的流水。但是业务方法里会有很多的if else，每种流水同步方式对应一个方法，而且都放在了一个service类里面。想到后面可能还会有新的同步类型，那么就还要加else if，还要再这个service类里面加代码，后面这个类肯定会很大，不好维护。
	最后想到用一个策略模式来写，我首先定义一个最顶层的接口，接口里面只有一些方法定义，比如同步方法，流水类型是否支持等等。然后定义了一个抽象类实现该接口，抽象类里面有一些共有的属性和方法，比如Redis锁的key，和加锁方法，解锁方法，具体的同步逻辑没有实现。
	然后每个类型流水都对应一个具体的Strategy策略类，继承了抽象的父类，并且在其中实现了自己具体的流水同步逻辑。每个流水策略类上都加了一个我自定义的注解，这个注解主要标注了这个流水的类型。
	然后定义了一个策略工厂，其中有一个Map属性作为策略类的容器，然后通过@Autowired将所有抽象父类类型的SpringBean都注入进来，用一个List接收。然后在一个init方法，通过@PostConstruct注解，因为@PostConstruct是在Bean实例化后，依赖注入完成的执行的一个扩展点，所以加了@PostConstruct的init方法在执行时策略工厂已经完成属性注入，能确保将所有的策略类都注入进来。init()方法的具体逻辑，就是循环策略类，然后将其put到Map容器中，其中key是流水类型，value就是对应的策略类。
	最后当调用同步流水接口，策略工厂会根据传入的流水类型参数，拿到对应的策略类，然后直接调用策略类的同步方法即可。
	这样如果后续还有新的流水同步类型，那么只需要新增一个流水类型的枚举，新增一个对应的策略类即可，其他代码就不用动。维护扩展起来很方便。

61.	介绍一下Redis	
	Redis是一个基于内存的，存储数据类型是key-value形式的非关系型数据库。因为Redis是基于内存的，相比于传统的数据库在磁盘进行IO，它的处理速度非常快。但是因为收到内存大小的制约，所以Redis一般作为缓存，存放一些热点数据，可以减缓数据库的压力。因为读取速度快，并且Redis是在进程间共享的，所以Redi在分布式场景中s也常被用来作为分布式锁。并且Redis中除了提供常见的数据类型像String，List，Hash，Set，Zset之外，还提供了像BitMap可以作去重判断存在，Hyperloglog，地理位置，Stream等的结构。并且Redis还提供了持久化机制，内存淘汰机制，支持lua脚本等。
	Redis是一种非关系型的数据库存储，所以不像MySQL那样表数据之间会有很多约束限制，数据之间可能还会有外键关联等等。所以Redis的数据之间没有关联性需要维护，新增删除等很自由。
	Redis对于命令的处理是单线程的，每条命令都是一个原子性的操作。

62.	Redis的几种数据结构
	Redis的key一般都是字符串，value有多种数据类型。
	String：可以存储普通字符串，数值类型，浮点型等等都是由String数据类型存储的。
	List：类似一个双向链表的结构，支持正向操作和方向操作。其中的元素顺序和插入顺序保持一致。可以用来存储有序列表。因为List的BLPOP和BRPOP命令，在移除元素时，如果没有元素不会直接返回nil，而是会阻塞等待，所以可以模拟一个阻塞队列。
	Hash：可以存储Java对象，类似一个Map结构，也是由多组field-value构成的。hash可以只操作其中的某个field。所以相比于直接序列化成json存储在String结构里，hash结构能直接操作其中的字段，这是hash的一个优势。
	Set：元素是无序的，且不重复。可以做一些并集，交集的操作，所以像共同好友类似的需求用Set很方便。类似Java中的HahSet
	ZSet：是一个可排序的set集合，Zset中的每个元素都带有一个score分数属性，可以基于score对元素做排序。类似Jav中的TreeSet，并且元素也不可重复。适合做排行榜，获取前几名等这样的场景。
	还有BitMap位图：可以作数据的去重，合并等。类似布隆过滤器。
	地理坐标
	Hyperloglog：做统计，比如访问量，点击量
	Stream等
	

63.	Redis的持久化机制
	Redis是基于内存的，数据都在内存中读写，所以如果重启的话内存中的数据就会丢失。为了避免重启后数据丢失，Redis提供了两种持久化机制，将能内存的数据保存到磁盘，待Redis重启后恢复数据作用。
	Redis天然支持两种持久化机制RDB和AOF。
	RDB：类似一个快照，当写操作达到配置的频率时，就会触发RDB。将内存中该时刻的数据记录下来，以二进制的格式存储的磁盘，RDB存储的真实的内存数据。我们可以用bgsave命令主动的进行RBD快照，bgsave也可以避免阻塞主线程，他会在后台异步的执行RDB快照操作。RDB存储的是真是数据，所以Redis在重启后，读取RDB快照恢复起来很快，直接按照RDB中的内容进行恢复即可。但是RDB是全量的复制内存中Redis的数据，所以这是一个很重的操作，如果操作太频繁的对Redis整体性能肯定是会拖累的。但是如果配置的频率较低，导致RDB执行的频率低的话，那么重启Redis恢复数据的话，从RDB恢复的数据很难是最新的数据，会丢失很多数据。
	AOF：AOF也是Redis提供的一种持久化机制，它的实现是，每次Redis进行写操作时，都会像AOF日志中追加该命令。所以AOF持久化文件中存储的不是真正的数据，而是一条条的Redis命令。Redis在重启后，会读取AOF文件，将其中的命令全部执行一遍恢复数据。因为AOF存储的不是真正的数据，所以恢复起来相较于RDB来说较麻烦。AOF持久化机制能很大程度上保证数据得准确性，因为是每次执行完一条写操作，都会到AOF同步该命令，所以执行完整个AOF文件后，可以得到最新的内存数据。
	但是AOF情况下，也可能发生数据丢失的情况，比如我们执行完写操作成功后，再将该命令写到AOF文件时发生宕机重启，那么后续Redis重启时就无法恢复该数据，产生数据丢失的情况。而且因为AOF日志的刷盘策略是有Always和EverySec和NO的情况，如果是Always是同步写回，如果是EverySec是每秒刷盘，如果是NO就有操作系统自己决定什么时候将AOF文件缓冲区的内存刷盘时机，如果是后两种，也无法时时刻刻保证数据的完整一致性，也可能在宕机重启后发生数据丢失。
	因为每次写操作都会发生同步写命令到AOF文件的过程，所以也会影响到主线程的执行效率。
	而且因为AOF是每次发生写操作时都会在AOF文件追加命令，所以可能会有很多冗余的中间命令，可能一条数据的最新状态经过很多的变化，每次变化的命令都被AOF记录下来，在恢复时都会执行，所以会有很多的无用操作。针对这个情况，Redis也有AOF重写的操作，当AOF大小达到一定阈值，Redis就会进行AOF重写操作，在进行重写时，会读取当前Redis中的所有键值对记录到新的AOF文件，然后将新的AOF文件替换现有的AOF。AOF重写也是在一个后台的子进程进行的，避免阻塞的主线程。而且为了解决AOF重写过程中又有新的增量数据产生，在重写过程中如果有增量数据产生，那么会将增量数据对应的命令，同时写到AOF缓冲区和AOF重写缓冲区，最后会将增量数据的Redis命令也写道写的AOF文件中。
	AOF的主要缺点就是恢复起来不够快，冗余的写命令，刷盘策略也会导致数据丢失。但是数据丢失少，更准确。
	RDB的主要缺点是：RDB发生频次不好确定，频次少了，丢失数据多，频次高了影响Redis性能。但是恢复快。
	为了兼顾两者优点，Redis在后面又提出了混合的持久化机制。大致的一个过程是在Redis进行AOF重写时，会执行一次RDB快照，RDB快照的数据会放到AOF的前半部，同时期间产生的增量数据也会以Redis命令的形式追加在新的AOF文件后。这样在Redis重启后，读取的AOF文件前部分是RBD恢复起来很快，后面的部分也保证是数据尽可能准确。

64.	Redis为什么采用单线程，为什么这么快
	Redis的单线程指的是：接收客户端请求->解析请求->进行数据读写操作->发送数据给客户端，这个处理Redis命令的过程，这个过程是由一个主线程完成的，所以我们常说的单线程是这个情况。
	首先Redis是基于内存的数据库，内存的读写速度是非常快的，所以往往制约Redis的瓶颈不是CPU的处理速度，而是内存或者网络带宽。当内存或者网络带宽跟得上的话，开多线程处理Redis命令带来的效率和线程的调度和切换的开销相比起来很可能根本没有优势。所以不如就采用单线程处理。
	而且采用单线程后，可以避免了多线程的竞争情况，省去了线程切换，调度带来的开销，也避免了死锁的可能。而且单线程模型下，Redis设计起来可以更加的追求效率，更好利用内存快的特点。比如Redis的String，List，Hash，Set这些数据结构在设计时，就不需要考虑多线程并发，线程安全这些情况，所以这些数据结构设计的会很高效，效率很强。
	而且Redis采用了I/O多路复用机制处理大量的客户端Socket请求，IO多路复用大致机制就是一个线程处理多个IO流，就是我们经常听到的select/epoll机制。简单来说，在Redis只运行单线程的情况下，该机制允许内核中，同时存在多个监听Socket和已连接Socket。内核会一直监听这些Socket上的连接请求活数据请求。一旦有请求到达，就交给Redis线程处理，这就实现了一个Redis线程处理多个IO流的效果。
	
	不过Redis在主线程外，是会有多线程情况的。比如处理文件，AOF刷盘是由异步后台线程做的，还有像释放内存，也是由后台异步线程做的，删除大key时，不能用del命令，避免阻塞主线程，用的时unlink异步删除大key等等。因为这些操作往往都比较耗时，所以如果在主线程做的话，很可能阻塞主线程，导致无法处理后续业务。


65.	Redis的过期key删除策略
	Redis使用的过期策略是惰性删除+定期删除两种方式配合使用。
	每个我们为一个Key设置了过期时间时，Redis会把key带上过期时间存储到一个过期字典中，这个过期字典存储了Redis中所有key的过期时间。
	惰性删除：当我们在查询一个key时，Redis会先检查该key是否存在于过期字典里，如果不在就正常读取。如果在还要判断该key是否已经过期，拿它的过期时间和当前时间比较，如果超过了当前时间说明该key已过期，那么就会将其删除。因为是在每次访问key时才判断是否过期，是否删除，所以惰性删除对CPU较友好，消耗系统资源低。但是因为过期的key不能及时清理掉，甚至当存在一个大key时，如果大key过期了，但是后续又很长时间没有对其访问，过期大key会在Redis存在很长时间，造成内存的浪费。所以Redis还结合了定时删除的策略。
	定期删除：每隔一段时间，从数据库中随机抽取一定数量的key，检查他们的过期时间，并删除过期key。如果过期key在这批数据的占比达到一定阈值，那么就会循环这一步再次抽取一批数据检查。
	Redis选择惰性删除+定时删除两种方式结合使用，尽量做到平衡CPU和内存使用。

66.	Redis的内存淘汰策略
	在Redis运行期间，如果内存达到最大运行内存的配置，那么Redis就会触发内存淘汰机制。内存淘汰策略大概有如下几种：
	不淘汰任何数据，而是不再提供服务，直接返回错误。
	淘汰数据的策略，又分为是否设置了过期时间的数据和所有数据两类。
		随机淘汰设置了过期时间的数据。
		淘汰最快要过期的数据
		设置了过期时间的数据中淘汰最久未使用的数据：LRU
		设置了过期时间的数据中淘汰最少使用的数据：LFU

		在所有数据范围内，所及淘汰数据
		在所有数据范围内，根据LRU，淘汰最久没有使用的数据。
		在所有数据范围内，根据LFU，淘汰使用最少的数据。

	LRU：在Redis对象的结构体中维护一个字段，用来记录该数据最后一次访问时间，触发LRU的淘汰策略时，会根据具体的LRU策略从数据范围内随机选取5哥值，然后淘汰最久没有使用的数据。
	LFU：在Redis对象结构体中维护一个字段，每次该数据被使用时，该字段值+1，也是每次随机选取一批数据，比较他们的访问次数，淘汰访问次数最少的那个。

67.	缓存雪崩，缓存击穿，缓存穿透
	缓存雪崩指的时，大量的缓存Key的TTL同时期到期，导致大量的请求直接打到数据库，给数据带来大量的压力。
	解决方案：
		设置TTL过期时间时，可以给一个随机时间，避免大量key的过期时间一致。
		设置多级缓存，尽量未能走缓存的数据考虑设置一下缓存，比如浏览器缓存，redis缓存，jvm缓存等。

	缓存击穿一般指的是：热点key到期失效了，并且该key的缓存重建业务非常复杂，因为是热点key所以会有大量的并发直接打到数据库，并且该key缓存重建比较复杂，短时间内缓存一值每重建好。数据库就会持续的受到大并发，带来负载的隐患。
	解决方案：
		利用互斥锁解决缓存击穿的问题，当访问缓存没有命中时，此时线程获取抢占一个互斥锁，抢到锁的线程会去访问数据库，然后将数据在会写到缓存，最后释放锁。而没有获取到锁的线程，会休眠一段时间后，再次去重新读取缓存。互斥锁保证缓存没有命中时，同一时间只有一个线程去读数据库，并且新建缓存，避免突然的大并发打到数据库。但是互斥锁会让多线程串行化执行，降低了并发性能，效率下降，但是能尽量保证数据的正确性。
		逻辑过期解决方案：我们不为key设置TTL，而是在代码里判断key是否过期。为缓存的数据设置一个过期时间的字段，当Redis命中数据后我们自己判断该数据是否过期。如果过期了，那么当前线程回去新开一个线程去进行缓存重建，并且通过互斥锁保证同时只有一个线程在进行重建缓存的动作，然后直接返回过期的数据。其他线程发现数据过期了，但是因为无法抢占到锁，也会直接返回旧数据。直到后台线程完成缓存重建的工作，才会读取到正确的缓存数据。所以逻辑过期+异步重建缓存会导致一定的数据不一致的情况。
	缓存穿透：请求过来的数据，即不再缓存中，在数据库中也不存在，所以这种请求每次都会直接打到缓存。如果这种不友好的请求并发量很高，会给数据库带来很高的负载。
	解决方案：
		在请求进来时就做严格的参数校验，一般这种不存在的参数，是不符合业务规律的，所以应该能判断出来。
		缓存空值，如果缓存没命中，并且数据库也没命中，我们可以为其在缓存中缓存一个空值，后续在进来的请求直接从缓存返回控制给他。
		通过bitmap或者布隆过滤器判断该请求是否有对应的数据在数据库中：我们可以用布隆过滤器来在写入数据库时，对数据做一个标记，当后续用户请求进来时，先通过布隆过滤器进行判断，如果不存在就不会打到数据库。这样这样的不友好的请求只会打到Redis和布隆过滤器，保护了数据库。不过无论是bitmap和布隆过滤器都有一定的误差，不是百分百准确。

68.	Redis做分布式锁
	Redis是独立于JVM进程之外的，所以在分布式场景下，每个JVM进程的所有线程都会被Redis锁控制住。
	Redis自带一个setnx命令，当key不存在时才能set数据即setnx命令执行成功。所以setnx命令能保证多个线程同时执行setnx命令时，只有一个线程能成功，即只有一个线程能抢到锁。当抢到锁的线程执行delete key命令时，其他线程有有机会抢到锁了，相当于释放锁。
	而且因为Redis是基于内存的，无论是抢锁还是释放锁，性能都非常高，而且支持集群高可用，所以Redis常被用来实现分布式锁。
	
	Redis实现分布式锁需要注意几个点：
	1.虽然锁被某个线程抢到了，但是如果有其他线程执行了del 命令，锁还是相当于被释放了。比线程A执行期间线程自动过期了，然后线程B抢占到了锁。再线程B执行期间，线程A执行完了，线程A就回去执行解锁逻辑，就会释放掉锁，此时线程B还在执行着，但是锁被线程A释放了。所以我们要在释放锁的时候判断释放的锁是不是当前线程持有的锁。具体一点就是每个线程抢到锁时，key都是一样的，存的value是当前线程的标识，每个线程在释放锁时，会去比对当前线程标识和当前value中存放的标识是否一致，不一致说明该锁是别人持有的不能删除。就像上述的A线程在释放锁时，redis中存的时线程B的标识，和A线程的标识不一致。
	2.加锁时是一个原子命令，释放锁时也要保证时一个原子操作。但是释放锁时会判断锁是不是自身持有的，然后在释放锁，所以Redis通过lua脚本，在Lua脚本中判断是否是自身持有的锁逻辑，然后删除锁。lua脚本能保证多条Redis操作的原子性。
	3.加锁时要带上过期时间，避免业务阻塞了，但是锁一直没有释放。
	
	Redis分布式锁的一些缺点
	1.Redis实现的分布式锁，是不能重入的，即获取锁的线程，不能再次获取锁。
	2.超时自动释放：Redis锁，如果锁对应的key到期了，那么就相当于自动释放锁，即使持有锁的线程还在执行业务，其他线程也能够获取到锁。
	

69.	Redis缓存怎么保证数据一致性
	使用Redis作为缓存时，为了尽量和数据库数据保持一致，我们采用的策略是：
	读操作时，如果命中就直接返回缓存数据，如果没有命中，则会到数据库中读取数据，然后再将数据写到缓存中，将读到的数据返回给用户。
	写操作时，会先更新数据库中的数据，然后将缓存中的数据删除。
	其中读操作没有命中时，在从数据库读到数据时可以直接返回，然后缓存的重建工作可以通过异步的方式重建，并且可以用互斥锁来保证同时只有一个线程在重建该数据的缓存。如果重建缓存期间读该数据的请求很多，那么这些请求都会打到数据库中，要避免这种情况的可以将都数据库的操作和重建缓存都放在一个锁里控制，其他线程进来没有抢到锁时，会休眠等待。这样会导致并发度降低，效率下降，但是能尽量保证数据的正确性。
	写操作时，涉及到数据库中数据的变更的话，就要更新缓存中的数据了。但是缓存更新的时机，选择的是在数据库更新后，直接删除缓存中对应的数据，缓存的重建工作交给后续的读线程。
	为什么是删缓存：数据库更新后，缓存中的数据就和数据库不一致了。为什么是删除缓存而不是更新缓存，主要是考虑到两个情况：
	1.无效写缓存操作：如果该数据在每次更新都重建缓存的话，可能会有很多无效的更新动作。因为缓存更新后，只有后续有读操作进来，缓存才算生效。所以在读操作进来之前的几次更新动作，都是无效的，所以我们在更新数据库后，采用删除缓存，将缓存的重建动作交给后续的读线程。
	2.写缓存时导致的数据不一致：而且删缓存可以尽量避免一些并发操作导致的线程不一致的情况。比如两个线程都更新了数据库后，都要更新缓存。比如A线程更新数据库后，在进行更新缓存的动作。这个时候B线程也发生了更新数据后，然后再更新缓存的动作，而且B线程已经更新完了缓存后，A线程还在更新缓存动作，就会导致A线程缓存又改成A当时在数据库中写的值，导致缓存和数据库数据不一致的情况。删缓存的就可以尽量避免多线程写缓存时导致的数据不一致的问题。

	删缓存的注意点：先操作数据库还是先操作缓存
	要先操作数据库，在删缓存。无论是先操作数据库，还是先删缓存，都可能出现多线程读写导致的数据不一致的问题。
	如果先删除缓存，在操作数据库：写操作时，完成了一次读操作。比如A线程先删缓存，然后去更新数据库，在A更新数据库时，有读线程进来，读线程就会发生缓存没命中，然后读数据库读到了旧的数据，并且将旧数据更新的缓存中了。在A更新换数据库后，就导致了缓存和数据库不一致的情况，所以在操作数据库的期间有读线程进来，就会触发缓存更新，导致缓存更新为旧数据，而且因为数据库写操作是要稍微耗时些的，这种情况还是很可能发生额。
	如果是先更新数据库，在删除缓存：读操作期间，完成了一次写操作。比如线程A读缓存发现缓存没有命中，然后去数据库读数据重建缓存。如果此时进来一个线程B更新数据库操作，并且线程B更新王数据后，删除了缓存后，线程A还没执行完。后续线程A完成后，就会将缓存中的数据更新为当时读到的旧值，最终导致缓存数据库数据不一致的情况。但是在读操作期间，要完成一次写数据库操作，其实概率是很低的。因为读操作很快就结束了。所以要先操作数据库，在删除缓存。

	注意点：保证删缓存成功，比如可以用一个消息队列存放删缓存的任务。由消费者来删缓存，消费任务失败的话，再从队列中冲去获取任务，能保证一个重试删除的机制。如果超过一定次数还是失败，那么就需要像业务层报错了。
	

70.	Redission分布式锁	
	用Redis做分布式锁的一些缺点：
	1.Redis实现的分布式锁，是不能重入的，及获取到锁的线程，不能再次获取到该锁。
	2.超时后锁会自动释放：锁的TTL到期后，就相当于自动释放了，即使刚才持有锁的线程还在执行业务中，到期后其他线程就会获取到锁进行操作，没有一个续期的机制。
	在使用Redission时，如果我们不想让分布式锁超时自动到期，不传入释放时间，Redission会用一个看门狗的机制，然后会定时的调用一个方法为锁续期。


71.	volatile
	因为按照JMM Java内存模型的说法的话，JMM规范了Java虚拟机和计算机内存如何协同工作的，比如规定Java线程如何合适能看到其他线程修改后的共享变量，以及如何不同的访问共享变量。
	volatile修饰的共享，能保证每次由线程对其进行写操作时，都会把共享变量的最新值刷新到主存中，并且会通知其他线程中的该变量缓存失效，后续其他线程在进行读写时就回到主存中获取到最新的数据，
	被volatile修饰的变量会在读写操作的前后，加上各种特定的内存屏障来禁止指令重排，来保证有序性。因为在不影响单线程运行结果的情况下，计算机为了最大程度的发挥计算机的性能，会对机器指令做重排优化，通过内存屏障可以禁止计算机做指令重排序。
	底层原理，主要是用到了操作系统层面的一个LOCK前缀指令，会让当前处理器中的写操作导致其他处理器中中的缓存失效，并且会将数据马上写回主存。

72.	synchronized
	synchronized是JVM层面实现的一个同步互斥锁，基于Monitor管程机制实现的，底层依赖于操作系统的互斥原语Mutex，因为涉及到操作系统内核的切换，是一个重量级锁，性能较低。但是在JDK1.6对sync做了优化，通过偏向锁，轻量级锁，自适应自选等来减少sync的开销，性能得到了很大的改善。
	偏向锁：偏向锁是一种针对加锁操作的优化手段，指的是这个锁会偏向于同一个线程，很多情况下竞争这个锁的线程是同一个。针对这个情况，加sync锁是做了优化手段，即偏向锁。JVM会默认是开启偏向锁模式的，为每个新创建的对象都设置为偏向锁模式，不过偏向锁模式是有个延迟时间的，虚拟机会在启动后有4s的延迟，会对4s后创建的每个新对象开启偏向锁模式，4s前创建的对象都是无锁模式，进行锁操作时默认加的是轻量级锁。偏向锁模式下，每个新建的对象的对象头的的Thread id默认是0，表名该对象处于可偏向但未偏向状态，也叫匿名偏向状态。
	当锁对象被线程尝试获取时，会先检查mark word中存储的thread是否是当前线程id，如果不是，会默认通过CAS的方式，更新对象头中的thread id为当前线程id，cas的期待值是0。所以如果锁对象是首次被线程获取，那么此时对象头的mark word中存的thread id就是0，即cas更新成功，意味着偏向锁获取成功。后续当该线程再次尝试获取锁时，因为锁对象中存储的thread id就是当前线程id，所以偏向锁再次获取成功。可以执行同步代码块。在只有一个线程的竞争情况下，偏向锁通过判断mark word中的线程id，来避免很多无效的加锁解锁操作。
	如果处于偏向锁状态的对象，此时又来了一个其他线程来竞争该锁，那么偏向锁会触发锁升级的操作，走偏向锁撤销，升级为轻量级锁。
	轻量级锁：也是sync加锁的一个优化手段，一般针对的场景是，多个线程交替的执行同步块，当一个线程执行完一个同步块后，其他线程才回去执行同步块。这种情况的并发度很低，没有必要直接使用重量级锁。
	当一个偏向锁发生了其他线程竞争的情况是，偏向锁会先走偏向锁撤销流程，将对象置为无锁状态，然后再升级为轻量级锁，同时对象处于轻量级锁锁定状态。如果处于锁定状态时，又有其他线程尝试获取该锁，那么此时会同时有多个线程在竞争该锁，不再是线程交替执行的一个情况。轻量级锁就会升级为重量级锁。而且线程B即没有获取到锁的线程，会先进行一个自适应的自旋，如果在该时间段内锁释放了，那么线程B就可以抢到锁，执行同步块，避免线程阻塞唤醒的操作。如果自适应自旋时间打到临界值，线程B才会发生阻塞。
	重量级锁：当升级为重量级锁时，也意味当前的线程竞争比较大。所以重量级锁能保证同一时刻只有一个线程能访问到同步块，其他线程处于阻塞的状态。所以会涉及到很多的阻塞唤醒操作，消耗较大。

73.	Java线程状态
	Java线程状态对应着Thread类中的state这个枚举，对应有如下几种状态
	NEW，Runnable，Blocked，Waiting，TimeWaiting，Terminated。
	当我们new 一个Thread对象时，这个对象就处于New状态。
	当我们调用Thread对象的start()方法时，Thread处于Runnable状态，此时线程可能会被CPU调度到，也可能正在等待CPU的调度。
	Blocked：一般是在抢占sync互斥锁时，抢占失败的线程处于Blocked。
	Waiting：一般通过wait()，join()方法，会阻塞当前线程进入WAITING状态。
	TimeWaiting：sleep()指定时间后，当前线程会进入TimeWaiting状态，到期后又变为Runnable状态。
	Terminated：线程执行完毕后进入终结状态。

74.	Thread的相关方法
	join()：线程对象调用join()方法时，会阻塞当前线程，直到线程对象执行完毕，当前线程会再次进入就绪队列。可以通过interrupt()方法打断因join()方法阻塞的线程，让其直接回到就绪队列。
	sleep()方法：会让当前线程主动休眠指定时间，放弃了CPU的使用，将CPU让渡给其他线程。也可以被interrupt()方法打断，直接进入就绪态。
	yield()方法：也是当前线程让如CPU，但是CPU可能还会调度到执行了yield的方法，而sleep在休眠时间结束之前CPU都不会调度到因sleep阻塞的线程。
	wait()方法：结合sync同步代码块，是java的管程默认实现。会让当前线程让渡出CPU，并且释放sync锁。后续该线程需要其他抢占到sync锁的线程通过notigy/notifyAll唤醒。
	interrupt()方法：像因为join()，sleep()处于阻塞的线程，如果调用了因为这些方法处于阻塞状态的线程对象的interrupt()方法，那么阻塞的线程会被打断，抛出一个Interrupt异常，从阻塞状态变为runnable状态，进入就绪队列。并且将中断标志位重置为false。
	interrupt如果线程处于运行状态的线程对象，会将中断标志位置为true

75.	threadlocal
	主要就是解决多线程访问共享变量导致的线程不安全的问题，通过threadlocal可以将变量变为线程的局部的变量，避免被其他线程干扰。具体的实现就是每个线程都有一个threadlocalmap属性，再通过threadlocal对象调用set方法时，会拿到当前thread对象的threadlocalmap属性，然后将数据set到threadlocalmap中，其中key是threadlocal对象，value就是数据。
	后续当多个线程通过同一个threadlocal对象的get方法时，会到各自的thread对象的threadlocalmap中获取到各自的数据，实现了隔离。

76. AQS和ReentrantLock
	AQS是一个用来构建锁和同步器的框架，使用AQS能简单且高效地构造应用广泛且高效的同步器，比如ReentrantLocak，可以基于AQS这个框架构建出一个符合我们自己需求的同步器。
	AQS的核心思想就是，如果被请求的共享资源空闲，则将请求线程设置为有效的工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占用，那么就需要一套线程阻塞，等待，唤醒的机制，这个机制AQS是用CLH队列锁实现的，重入锁是基于一个int类型的state属性来控制的。每次重入state都会加1，每次释放state都会减1.

	ReentrantLock是基于AQS框架实现的一个互斥锁，很多场景可以用来代替sync锁，但是他比sync多了一些功能，比如可以在获取锁时设置超时时间，可主动中断等待的线程，支持多个条件变量。

76. Hashmap
	Hashmap是一个存储key-value形式数据的容器，其中的key必须唯一，而且能存null值。Hashmap底层的数据结构是链表+数组+红黑树的形式，再往Hashmap中put一对键值对时，hashmap会根据key计算出hashcode，然后通过一个特定的hash散列函数，计算出该key对应在数组上的下标值。具体的hash函数是：根据key得到hashcode后，将hashcode的高16位和低16位进行异或运算得到hash值。将得到的hash值，与数组长度减一后，进行按位与运算后得到最终的数组下标。
	根据key得到hashcode，hashcode高16位和低16位进行异或运算后得到hash值，然后hash值与数组长度-1进行按位与运算得到最终的数组下标位置。当时分析为什么这样进行散列时，还挺费一番功夫的。因为hashmap的数组长度都是2的n次幂，所以n-1后，低位全部都是1，如果数组长度较小，那么长度n-1后高位都是0，低位都是1。最后再做与运算时，因为高位都是0，那么无论hash值的高位是什么，结果都会是0。所以很可能出现这种情况，两个不同key对应的hash值的高位不同，但是低位相同，那么如果直接将hash值与n-1按位与的话，结果是一样的，产生了hash冲突。产生这个冲突的原因就是hash值的高位在按位与运算中没有起作用，所以hashmap采取的办法就是将hashcode的高16位和低16位进行异或运算，这样在进行最后的按位与操作时，即使n-1后的高位都是0，hashcode的高16位也起作用了，会使得散列范围更加广泛。为什么要按位与，因为本质上是要根据最终的hash值与长度进行一个取模操作的，因为长度是2的n次幂，正好可以将取模运算等价于与n-1按位与运算，与元算比取模运算高效很多。
	如果在put元素时，发现散列后在数组的下标一样，那么久产生了hash冲突。hashmap解决hash冲突的方式是连地址法，会将产生了hash冲突的数据，构成在链表的方式放到刚才散列得到的数组下标位置处。
	后续在进行查询时，如果发现该位置处是一个链表，那么会沿着链表往后遍历到该key对应的数据。因为链表的查询性能是O(n)，在数据很大是效率较低，后续引入了红黑树来重新组织产生hash冲突的这些节点。在红黑树上进行查询时效率是O(logn).
	Hashmap的查询效率很高，直接通过key就能拿到，但是空间占用率较大。相当于用空间来换时间的思想。而且Hashmap是一个线程不安全的容器，在并发场景下，要考虑到这点。可以考虑线程安全的容器，比如Hashtable，ConcurrentHashMap。但是Hashtable在进行写操作时是锁主整个table的，效率很低，ConcurrentHashMap应用的分段锁+CAS的优化手段，效率较高，使用的很多。

	HashMap中有个加载因子，表示Hashmap能容纳的数据的最大程度，数组长度*加载因子表示Hashmap能容纳的最大数据量，当Hashmap中的元素达到这个值时，就会触发一个扩容机制。数组长度会扩容两倍，元素会进行依次遍历散列到新的数组中。如果链表的长度达到8，并且数组的长度达到了64时，会触发树化的机制，链表会被转成红黑树。

77. ConcurrentHashMap
	ConcurrentHashMap的key和value都不允许为null。HashTable在保证线程安全方面是通过为整个table加上sync锁，性能较低。ConcurrentHashMap在保证并发的前提下同时也兼顾了性能。
	在JDK1.7之前，ConcurrentHashMap底层数据结构主要是分段的数组+链表实现。他将数组分成一段一段的Segment，在进行写操作时，每次上锁都只锁住其中的一段数据，其他数据的读写能正常进行。
	在JDK1.8时，ConcurrentHashMap的底层结构和HashMap一致，采用数组+链表+红黑树的方式。并发控制主要是通过sync+cas自旋来实现的。在进行put时，如果通过hash函数计算的得到的数组位置上没有元素，那么会通过cas的方式将元素放到这个位置上，cas时指定的期待值时null，更新值是要put的元素。CAS能保证多个线程都在这个下标位置处进行put元素时，只有一个能成功。后续cas失败的线程会走else逻辑，将元素挂到该位置的链表上。
	当出现要将元素挂到链表上时，sync只锁住这一个数组下标，锁的粒度更细。不会影响到其他线程访问其他位置。

78. ArrayList和LinkedList

79.	乐观锁和悲观锁的介绍，对比两者优劣，适用的场景
	乐观锁和悲观锁都是锁的一种设计理念。
	悲观锁：悲观的认为程序中的并发情况很严重，会假定每次访问时都会发生线程不安全的情况，所以会严防死守，每次只允许一个线程执行同步代码块，其他线程阻塞。因为线程的阻塞唤醒，涉及到操作系统内核的切换，所以有较大的性能消耗，而且每次只能有一个线程执行同步块，所以并发度不高，降低系统的吞吐量。但是能保证数据的一致性，正确性。所以悲观锁适合并发度高，需要严格控制并发的情况。能在并发冲突概率很高的情况下，保证只有一个线程执行逻辑，保证数据的正确性。
	乐观锁：乐观锁认为发生线程安全问题的可能性很低，多数情况下都不会发生，所以没有必要上来就加锁。不应该在这种情况下，让所有线程串行执行。乐观锁保证线程安全的方式，是在对数据进行更新时判断数据和访问时的数据是否一致，不一致说明有其他线程做了修改，发生了线程竞争，不能进行后续操作了。乐观锁避免使用了锁，所以不会有线程状态的切换，比如阻塞唤醒，所以消耗较小。因为没有加锁，所以能保证系统的并发量。但是可能出现一种情况，多个线程都在执行这个业务，由于使用的乐观锁，这些线程在一开始都能进来，但是只有一个线程能执行成功，那么其他线程就相当于做了无用功，白白浪费了。所以乐观锁适合并发度比较低的情况，而且要不影响到系统的并发度和吞吐量。

80.	说一下JVM的运行时数据区
	内存作为CPU和磁盘的桥梁，会把磁盘中的程序数据加载到内存中运行。一个Java程序在被加载到内存时，就对应着了一个JVM进程。JVM的内存布局规定了Java程序在运行时的内存申请，分配，管理等策略，它定义了若干种程序运行时会使用到的运行时数据区。JVM的运行时数据区大致可以分为两种：一种是随着JVM虚拟机启动而启动，销毁而销毁，比如堆，方法区。一种是每个Java线程都有一份的，并且随着Java线程的创建而创建，销毁而销毁，比如虚拟机栈，本地方法栈，程序计数器等。所以像堆和方法区，是所有线程共享的，每个JVM进程对应一份。
	几乎所有的对象和数组都是在堆上分配，堆会被分为新生代，老年代，而新生代又被细分为伊甸园区，SurvivorForm区，SurviviorTo区。堆是垃圾回收的主要区域，因为机会所有的对象的分配都是从堆上开始，而且绝大部分的对象的创建和销毁都是新生代完成的。一般会将堆的起始内存和最大内存设为同一个值，这样能避免程序在运行时扩容，GC后又发生缩容的情况，避免Java在运行时频繁地重新计算分配堆区的大小。
	方法区在JDK1.7及之前的实现是永久代，在1.8之后的实现是元空间。两者的最大区别就是永久代用的是JVM的内存，而元空间用的是本地内存。这样元空间的最大可分配空间受本地可用内存限制，显然回比原来虚拟机分配的永久代大很多，避免因为永久代触发的Full GC，因为对永久代的回收，对类的回收和卸载是很困难的。方法区中主要存放着类的元数据信息，方法元信息，运行时常量池等。而且在1.7之后原本在永久代中的字符串常量池也被移到堆中了。
	虚拟机栈是每个线程独有的，它的基本单位是栈帧，每次一个方法的调用都会入一个栈帧，一个方法的返沪都会弹出一个栈帧，如果无限制的递归调用就会造成StackOverFlow栈溢出。而栈帧中又可以细分为局部变量表，操作数栈，方法返回地址等。局部变量表主要存放方法参数和方法内定义的局部变量，操作数栈用来保存计算的中间结果和计算过程中的临时变量。无论是局部变量表还是操作数栈，随着方法的调用结束，栈帧出栈而销毁。

81.	新生代对象的分配和回收过程
	因为几乎所有的Java对象都是在Eden区被new出来的，我们大致看一下新生代对象的分配与回收过程。
	当需要创建对象时，首先会在Eden区进行内存分配。随着程序的运行，在Eden分配的对象越来越多，直到Eden满了。这个时候会触发MinorGC，堆新生代进行回收。开始MinorGC，此时会停止用户工作线程，根据垃圾回收算法，判断Eden区中的哪些对象是垃圾，哪些还是使用，将还在使用的对象晋升到Survivor区，并且为刚才晋升到Survivor区的对象分配一个年龄计数器值为1.Eden区中的垃圾对象被销毁，此时Eden区空了，两个Survivor区有一个有晋升的对象称为SurvivorFrom区，一个还是空的称为SurvivorTo区。
	继续在Eden区创建对象，当Eden园区再次满时，再次触发MinorGC，还是对新生代进行垃圾回收。通过垃圾回收算法回收Eden区中的垃圾对象和Survivor中的垃圾对象，Survivor区中存活的对象会从SurvivorFrom晋升到空的SurvivorTo区，并且年龄计数器+1，然后伊甸园区中的存活对象也晋升到SurvivorTo区，年龄计数器赋值为1。然后SurvivorFrom区空了，在下一次MinorGC中成为SurvivorTo区，SurvivorTo成为了SurvivorFrom区。 
	随着上述步骤的进行，当某一次再次触发MinorGC进行Eden，Survivor区回收时，发现存活的对象的年龄计数器达到了15，此时这类对象会直接晋升到老年代。
	在上述新生代对象的分配和回收中可能会出现一些特殊情况：
		如果再将Eden区存活的对象晋升到Survivor区时发现Survivor放不下，那么会将该幸存的对象直接晋升到老年代。
		如果有一个超大内存分配，在Eden区发现内存不够了，会触发MinorGC，MinorGC后Eden区还是不够，然后会判断老年代能不能放下，如果还是放不下会触发FullGC，能放下就直接放到老年代了，如果还是放不下那么就OOM了。

82.	MinorGC，MajorGC，FullGC
	MinorGC主要是针对新生代的GC，在伊甸园区满时会触发MinorGC，会回收伊甸园区，SurviviorFrom和SurvivorTo区。MinorGC发生的频率比较高，因为大部分的对象的存活周期都比较短暂，进行MinorGC时也会触发STW机制，但是MinorGC的回收速度会很快，体验较好。
	MajorGC主要是针对老年代内存区域进行回收，比如从新生代晋升来的对象。但是好像只有CMS GC垃圾回收器可以单独收集老年代，所以一般在实际工作中说的MajorGC可能不止对老年对进行回收，会有些模糊。
	Full GC时一个完整的垃圾回收，会检查并清理整个堆内存，包括新生代和老年代。会导致较长的停顿时间。
	

83.	OOM问题的处理思路
	要解决OOM异常，一般的手段是先通过内存映像分析工具，比如Eclipse Memory Analyzer对dump出来的堆转存储快照进行分析，重点是确认内存重点对象是否是必要的，是否有异常的大对象。然后分清楚到底是内存泄漏还是内存溢出了。
	如果是内存泄漏了，就是对象明明不再使用了，但是还有引用指向导致存活。可以进一步通过工具，比如JProfile查看泄露对象到GC Roots的引用链，然后找到泄露对象是通过怎样的路径与GC Roots相关联并导致垃圾收集器无法自动回收他们的。掌握了泄露对象的类型信息，以及GC Roots引用链的信息，就可以比较准确地定位出泄露代码的位置。
	如果不是内存泄漏引起的，也就是内存中存活的对象都是需要的，那么就要考虑虚拟机的堆内存是否足够，是否能够加大了。比如检查堆参数-Xmx与-Xms。看看物理内存是否还可以调大，或者检查大对象是否能够优化，生命周期较长的对象能否优化等等。

84.	说一下类加载过程
	首先是class文件加载阶段，根据全限定类名将这个类对应的字节码文件以二进制流的形式加载进内存。比如从本地文件系统进行读取加载。加载到内存后，会把字节流转换为对应的类元数据信息，方法信息，常量池等放到方法区中。并且生成一个Class对象，这个Class对象作为访问这个类的类型信息的入口。
	然后是链接阶段，链接阶段分3个步骤：验证，准备，解析。
		验证阶段：主要是做一些教研工作，比如这个字节码格式是不是符合JVM的标准，比如文件头校验。
		准备阶段：会为类变量做默认初始化操作，为它赋值一个默认的初始值。如果是final修饰的类变量，会在编译阶段就分配好具体的值了。
		解析阶段；会将常量池中的符号引用解析为直接引用，就是将原来描述目标的符号解析得到直接指向目标的指针或者偏移量，能直接访问到目标。

	链接阶段后是初始化阶段：主要是执行类的初始化方法，即clinit。这个方法主要是收集类变量的显示赋值动作和静态代码块。
	到这里类的加载动作就结束了。

84.	双亲委派机制
	在加载某个类的class文件时，Java虚拟机采用的时双亲委派模式，即把类加载过程优先交由父类加载器处理，它是一种任务委派模式。
	大致的过程是这样的：
	如果一个类加载器收到类加载请求，他不会自己直接先去加载，而是先把这个请求委托给父类加载器去执行。如果父类加载器还存在更上一层的父类加载器，则会进一步向上委托，请求最终到达顶层启动类加载器BootstrapClassLoader。一般每个类加载都有各自负责加载的class文件，如果父类加载器可以完成类加载任务，就成功返回。倘若父类加载器无法完成加载任务，会向下委托给子类加载器。
	JVM提供的的类加载器有：最上级的引导类加载器BootstrapClassLoader，下一级的扩展类加载器ExtensionClassLoader，在下一层的应用程序类加载器AppClassLoader。除此之外还可以用户自定义类加载器。
	
	双亲委派的意义：可以防止重复加载同一个class字节码文件。因为类加载器收到加载请求时，会先向上询问父级类加载器是否加载过，如果父类已经加载过了，那么就可以及时发现，保证数据安全。
 
 
85.	说一下垃圾回收机制和常见垃圾回收算法
	JVM运行时数据区涉及到垃圾回收算法的只要是堆和方法区，像虚拟机栈和本地方法栈虽然可能栈溢出，但是不会进行垃圾回收，直接出栈即可。所以主要是针对堆和方法去进行垃圾回收，而且是频繁的回收堆中的新生代，较少的收集老年代，极少收集方法区。
	垃圾回收机制一般分为两个阶段：标记阶段和垃圾清除阶段。
	
	标记阶段有两个代表性的算法：引用计数算法和可达性分析算法。
	其中引用计数算法：会对每一个对象，只要有任何一个地方引用了这个对象，则它的引用计数器加1，当某个引用失效时，引用计数器减一。当这个对象的引用计数器的值为0时，就表示这个对象不再被使用，可以被当作垃圾回收了。引用计数算法并没有被JVM的垃圾回收器选择使用，因为它有个知名的缺点就是没法处理循环引用的情况，会出现内存泄漏。
	可达性分析算法：会把一些活跃的引用，比如方法参数，局部变量，静态变量，常量池，持有的锁对象等作为跟引用GC Roots。它的思路就是通过这一系列的GC Roots作为起始点，从他们开始沿着引用链向下搜索，能搜索到的对象就是可达的对象，是活跃的不能被收集的。如果一个对象和GC Roots之间没有任何引用链相关的话，这个对象就是不可达的，会为其打上垃圾标记，等着回收阶段被回收。

	finalize机制：当一个对象经过可达性分析后，发现是一个垃圾对象，并且打上了垃圾标记。GC时发现这个对象重写了finalize方法，而且在finalize方法里面重新与GC Roots建立引用关系，那么这个对象会被复活，不会再这次GC中被回收。但是finalize只会被调用一次，只会起作用一次，下次如果这个对象还是可不达的，那么就会直接回收。

	清除阶段的算法我感觉主要是体现在内存整理方面：
	标记清除：一般清楚的话会通过维护一个空闲链表，把垃圾对象所占的内存地址添加到这个链表上，当需要分配新的空间时，直接从这个链表上申请。但是因为这样回收后会产生很多内存碎片，内存空间会被浪费掉，所以在清除阶段后还会有内存整理阶段。
	内存整理分为两种：复制算法，压缩算法
	复制算法：会将运行时内存分为两块，每次只会使用其中的一块，另一块空闲。在GC进行标记后，会将存活对象移动到空闲的内存，剩下的都是垃圾对象被回收。这个虽然清除的标记快，但是用到了两倍的内存，内存空间浪费了。
	标记清除压缩：在将对象区分好哪些是垃圾哪些是存活的对象后，会整理一下，把存活对象放到内存的一端，后面跟着垃圾对象。这样内存空空间就规整有序的分布，已用和未用的内存各自隔开，两者之间维系着一个指针作为下次内存分配的七十点。 之后创建对象时就从两者分界的指针处开始分配内存，然后再向后移动指针为新创建的对象的大小。避免内存碎片
	
				
86.说一下你知道的垃圾回收器：
	我感觉垃圾回收器一般都会基于两个方面来进行分析：一种时倾向于减少每次STW停顿时间，侧重于相应快，但是可能回收不彻底，会频发的进行GC；一种是倾向于吞吐量，减少总的垃圾回收时间，单次回收造成的STW的时间可能较长，但是回收的比较彻底，有一定的用户体验影响。
	Serial/Serial Old：像最开始的垃圾回收器Serial，它的主要特点是串行回收，也就STW停顿时间。一般Serial回收器会回收新生代，Serial Old会回收老年代。一般是单线程串行回收，意味着只有一个收集线程完成垃圾收集工作，而且和工作线程也是串行的，所以会停掉整个用户线程，直到它回收结束。它会有较大的停顿时间，不过会回收的比较彻底，高效，一般在单核CPU，单线程场景中使用。Serial串行回收器会作为一个兜底的方案，在其它垃圾回收器没有达到效果时，用Serial串行回收器进行彻底的回收。
	
	ParNew回收器：是针对新生代的垃圾回收器，在进行垃圾回收时它是多线程并行的，但是和工作线程还是串行的，所以也有STW停顿时间。但是相比较Serial而言，因为是多线程并行回收，能有效利用多核CPU，发挥硬件优势，减少STW停顿时间。

	Parallel Old：和ParNew类似，只不过是针对老年代的回收。

	Parallel Scavenge：JDK8默认的垃圾回收器就是Parallel Scavenge + Parallel Old，Parallel Scavenge相比于ParaNew主要体现在它侧重于应用的吞吐量，而且它有一个自动调节机制。我们可以通过VM参数，比如设定GCTimeRation时间比例，最大停顿时间，最大堆等，让虚拟机能自动调节各部分内存比例，年龄计数器等以满足我们的吞吐，达到我们的设置的要求。

	CMS：侧重于低延迟，一定程度上做到了用户线程和垃圾回收线程同时进行，在标记阶段还是会暂停整个用户线程，但是在清除阶段是和用户线程并发进行的，不会停止用户线程，一定程度上减少了用户线程的延迟时间。

	G1：通过内存区域分块Region，以Region块为单位进行回收，它的响应时间很低，STW停顿时间很短。不再是以分代为单位进行回收，以更小的Region单位进行回收，能更好的控制响应时间和吞吐量，尽量的满足我们预先设定的目标。

	ZGC：更加减少了停顿时间，响应更快。

87.	线程池
	如果每次用到线程执行一些异步任务时都是这样，就会造成频繁的创建和销毁线程。这是比较消耗系统资源的，而且没法复用我们创建的线程。线程池就可以帮我们统一的管理线程的创建，执行，销毁等动作，可以做到复用创建的线程，我们只需要往阻塞队列中提交任务即可。
	核心线程数：表示线程池中一直保持活动的线程数量，这些线程会一直存活，即使他们当前没有任务要执行。
	最大线程数：表示线程池中允许的最大线程数，当任务队列已满且活动线程数达到最大核心线程数时，线程池会创建新的线程，直到达到最大线程数为止。
	任务队列：用来存储等待执行的任务。当线程池的活动线程数达到核心线程数时，新的任务会被放到任务队列中进行等待。
	线程存活时间：表示当线程池中的线程数超过核心线程数时，多余的空闲线程的存活时间，如果在这段时间这些线程没有任务执行，那么这些线程会被回收。
	拒绝策略：定义了当任务无法被接受时应该采取的行动，常见的拒绝策略有抛出异常，丢弃任务，丢弃队列中最老的任务，以及自定义策略。
	任务执行超时时间：制定了任务在队列中等待的最大时间，如果任务等待时间超过这个时间，可以选择取消任务或者执行其他处理。
	线程工厂：用于创建新线程的工厂，允许你自定义线程的创建方式。

88.	大数据量分页查询的优化思路
	没用PageHelper做分页
	比如说分页查询，因为在大数据量的情况下，分页的偏移量越大，查询效率越低。可以通过子查询的方式来提高分页效率，比如按照create_time排序，然后取10001到10020个数据。那么我们可以现在子查询中查出符合条件的第10001条记录的create_time，然后在外层查询直接取create_time>子查询的create_time的数据取20条。因为子查询是可以走到索引的，而且一般建立的联合索引，而我们只查了create_time，所以还会走索引覆盖。比较高效。

	通过索引排序后，在进行limit：减少计算次数
	select * from table order by id limit 100000, 10


89.	难点
	sql优化：比如分页没有用pagehelper，exists，索引，语句语法等等
	多数据源导致的Spring事务失效
		@Primary 必须加此注解，不然报错，下一个类则不需要添加
		@ConfigurationProperties(prefix = "fee-report.datasource")
		实现接口 TransactionManagementConfigurer 方法，其返回值代表在拥有多个事务管理器的情况下默认使用的事务管理器
		你想连接两个数据库，就需要创建两个 SqlSessionFactory 实例，每个数据库对应一个

90.	gateway作用
	鉴权，数据清洗，路由，校验
	它是外部请求和内部服务的流量入口，作为系统的统一入口，提供内部服务的路由中转，给客户端提供统一的服务，可以实现一些和业务没有耦合的公共逻辑，比如认证，鉴权，路由转发，安全策略，防刷，流量控制等等。
	比如客户端（例如浏览器，移动端等）向微服务系统发送了一个请求。
	请求首先到达Nginx反向代理服务器，Nginx可以用于负载均衡和反向代理，它会接收客户端的请求，并将其路由到API网关。Nginx可能处理静态资源，如果请求时针对静态资源的，比如图片，CSS或者Javascript文件，Nginx可能会直接处理并返回响应，而不需要将请求传递给API网关或者其他微服务。
	API网关处理请求：API网关接收到请求后，可能会在执行一下操作：
		鉴权和认证，API网关可以验证客户端的身份并执行访问控制。
		请求路由：根据请求的路径，标识符或其他规则，API网关将请求路由到适当的一组微服务（比如order微服务的多个实例）。
		API网关整合Ribbon这样的客户端负载均衡器，将请求转发到具体的微服务

	可以做限流：根据配置的令牌桶填充速率，令牌桶的总容量，和具体的限流策略做限流
	可以作鉴权：可以通过配置过滤器，或者断言做一些鉴权，用户认证
	可以做路由：通过配置路由和断言，并且结合ribbon这样的客户端负载均衡，将请求达到具体的微服务中。
	

91.	过滤器和拦截器的区别和作用
	过滤器和拦截器是两种不同的概念，通常用于在Web程序中处理请求和响应的不同阶段
	1.运行顺序不同：过滤器是在Servlet容器接收到请求之后，但在Servlet被调用之前运行的。而拦截器则是在Servlet被调用之后，但在响应被发送到客户端之前运行的。
	2.作用不同：过滤器一般是在请求到达Servlet之前起作用，可以在过滤器中做鉴权认证，或者重新路由转发等。比如如果一个请求的认证信息不合法，过滤器就可以将这个请求路由转发到登录页面。拦截器一般是在Servlet调用后执行，可以抽出来一些统一的业务逻辑放到过滤器中，比如日志打印，统一异常处理（可以返回一个统一的，更友好的异常，而且要考虑是否和前端的统一异常处理适配）等等。比如有拦截请求，进行鉴权的拦截器，比如拦截登录请求进行刷新token的拦截器。

	实现HandlerInterceptor自定义一个拦截器，定义一个配置Bean继承WebMvcConfigurer，在其中的addInterceptors注入这个拦截器。

92.	Redis集群：主从模式 节点挂了怎么办，选举的过程，集群模式下持久化机制
	如果只有一台Redis，那么这台Redis挂了，那么就相当于没有Redis服务了，如果这台机器的硬盘数显了故障，那么Redis中的数据也无法在恢复了。
	为了避免这种单点故障，引入了Redis的集群，让多个Redis节点组成一个Redis集群。每隔Redis都保存同样的数据，如果其中一个Redis节点出现了故障，那么其他节点也还是能提供服务的。既然多台Redis保存同样的数据，那么怎么保证他们之间的数据一致性呢？
	Redis提供了主从复制模式来避免上述问题，这个模式可以一定程度上保证多台Redis数据的一致性，并且写操作只发生在主节点，从节点一般只处理读请求。当发生了写操作时，主节点会将最新的数据同步给从节点。从节点执行同步，尽量保证数据和主节点一致。
	
	主从节点之间的数据的具体同步细节：
	首先我们要通过slaveof命名指定Redis节点之间的主从关系，构成一个主从Redis集群。
	然后从服务器开始和主服务器进行第一次数据同步：
		首先是全量复制，主节点通过bgsave命令来生成一个RDB快照，将这个快照发给从节点，从节点清空旧数据，然后载入这个RDB快照。
		因为生成RDB快照的过程是异步的，所以这期间主节点可能会有许多新的写操作，产生了增量数据。而且在传输RDB快照和从节点在载入RDB快照期间也会产生新的增量数据。为了同步增量数据，主节点会将这期间产生的增量数据都写入到一个replication buffer缓冲区中。当主节点收到从节点的RDB快照加载好的响应后，就会把replication buffer中的写命令发给从节点，从节点执行这些命令后，就同步了增量数据了。第一次主从节点数据同步到这里就结束了，结果能尽量的保证主从节点的数据一致性。
	长连接传播命令：后续主从节点会维护一个TCP长连接，主服务器通过这个长连接将后续产生的写操作命令传播给从服务器，然后从服务器执行这些命令，老尽量保证节点间的数据一致性。因为这个同步动作是要频繁发生的，所以长连接避免多次的新建连接，断开连接的操作，不过长连接多的话也会消耗系统资源。

	增量同步：
	如果后续突然某个从节点发生了短时间故障，后续有恢复上线了，那么它肯定也是要先和主节点做一次数据同步的。因为之前在第一次建立主从集群时已经做过了全量的同步，所以如果发生了这种情况那么会发生一次增量同步。
	主节点在进行长连接命令传播时，不仅会将写命令发送给从节点，还会将写命令写到一个环形缓冲区中。有两个偏移量指针，一个是主节点的标记字节写到的位置，一个是标记从节点上次读到的位置。那么主节点会判断从节点上次读到的位置是不是还在这个环形缓冲区中，如果还在那么就从这个位置将后续的增量写命令同步给从节点，如果不再那么说明该位置已经被覆盖了，将采取全量同步的方式。
	
	怎么判断Redis某个节点是否正常工作：
	Redis主节点会默认周期的发送ping命令，根据响应来判断从节点的存活性和连接状态。
	从节点也会周期的发送命令给主节点：告诉其当前的状态信息和同步偏移量信息

93.	Redis集群：哨兵模式
	在主从模式的集群中当主节点挂了的话，那么需要我们人工介入，重新指定新的主节点，，让其他节点称为主节点的从节点，还要通知客户端新的主节点的位置。这显然很麻烦，后续Redis通过哨兵机制来实现了主节点故障的自动转移。它会检测主节点是否存活，如果主节点挂了，那么会从从节点中选出一个作为新的主节点。
	哨兵是一个特殊的Redis进程，类似一个观察者节点，观察监控主从节点。哨兵会每隔1s像主从节点发送ping命令，如果收到响应那么就认为它们正常工作。当哨兵发现主节点没有正常的响应它的PING命令时，会将其置为主观下线状态。因为可能是因为网络拥塞，造成的哨兵没有及时收到响应，主节点其实并没有挂掉。所以哨兵一般也是集群模式。当一个哨兵将一个主节点置为主管下线后，会去询问其他哨兵节点是否也认为主节点是主观下线的。如果投票数超过了配置的quorum的话（一般是一半+1），那么就主节点置为客观下线，主节点发生故障了，要进行重新选举了。
	首先哪个哨兵节点来进行选举呢？会先从哨兵节点中选出一个leader哨兵。大致的规则就是，先发现主节点主管下线的哨兵，将其作为候选者，然后询问其他哨兵节点是否也认为主节点是主管下线的（也就是没有收到主节点的PING命令响应）。认为的话就赞成，当赞成票超过配置的quorum时，这个候选者哨兵节点就成为leader哨兵节点，并且主节点被标记为客观下线。
	现在开始故障转移了：
		从故障节点的所有从节点中选出一个，将其作为新的主节点。具体的筛选规则大致如下：将网络状态不好的从节点剔除（有个配置会记录之前主从节点的超时断链次数），根据这个剔除网络不好的从节点。然后在网络较好的节点中选出优先级最高的，从节点有一个slave-priority配置，可以将机器配置好的从节点的优先级配置的高一些。如果有多个相同优先级的话，会判断这些从节点的复制进度，复制进度越大，那么它的数据越新。如果还是有多个，那么就会比较从节点的ID，ID小的作为新的主节点。
		选出了新的主节点，那么将其他从节点都指向新的主节点。哨兵leader向所有其他从节点发送slaveof命令，让他们称为新的主节点的从节点。
		哨兵会通过发布订阅的方式，像客户端订阅的频道中发布新的主节点的地址信息，帮助客户端切换新的主节点地址。
		继续监视下线的主节点，如果上线了，让其成为新的主节点的从节点，并且进行数据同步。

93.	Redis的IO模型

94.	统一异常处理：友好，适配前端
	系统中配置的有全局异常处理器，通过@ControllerAdvice注解标识这是一个全局异常处理器。
	然后我们将系统可能出现的异常分成了两种：一种是我们定义的一些异常枚举，一种是Exception，RuntimeException这些的系统异常。
	所以在全局异常处理器中定义了两个异常处理方法：
		方法1只处理我们自定义的异常，返回一个统一结果Result，将异常中的描述，Code放到这个Result中返回。
		方法2只处理Exception类型的异常，将其作为系统异常，返回一个统一的Result，将异常的Message放到Result中。
	这样就是不会直接把异常返回给前端用户，出现异常了对用户体验会更友好。
	而且这个统一的返回结果是要匹配前端配置的响应拦截器的，因为我之前写过一点前端的代码，前端里面配置的相应拦截器会校验返回结果中的state字段，所以后端中返回的统一Result中，也有state字段。

95.	Transactional失效场景
	首先要保证Transactional标注的类，或者标注的方法所在的类要是一个SpringBean，能被Spring管理，只有能被Spring管理的类，才会走到Spring通过AOP切面实现的Spring事务。
	比较典型的一些事务失效的场景：
		1.异常没抛出来，在catch块中被吃掉了：比如我们有两个方法，方法A调用方法B，并且在A方法中catch住了B方法的异常，而且没有在抛出去。那么当方法B出现异常时，因为我们默认的Spring事务传播机制是PROPAGATION_REQUIRED，所以B不会开启新的事务，而是整合到A事务中，两者公用一个事务。这个时候如果B出现了异常，那么在B方法中，这个事务会认为需要回滚，但是在A方法中因为异常被捕获导致且没有跑出来，A中会继续提交事务，最后会导致报错的情况。
		2.同一个类中方法的互相调用方式不正确：如果直接调用的话，其实相当于用this，但是Spring事务是依赖代理对象实现的，而this是一个普通对象。我们要拿到Spring容器中的代理对象进行调用，所以可以直接注入自己，然后用注入进来的对象进行调用。
		3.在多线程环境中可能造成事务失效：因为Spring的事务实现是和当前线程绑定的，当需要开启事务时，会将拿到数据库连接对象存到threadlocal中，多个方法都用同一个数据库连接对象保证了这多个方法都受到同一个事务控制。如果是多线程情况下，那么每个线程用的数据库连接对象都是不同的，每个数据库连接对象都会创建一个新的独立事务。
		4.Transactional注解只对public方法起作用。
	

96.	数据库的优化：分库分表，索引等等
	我们公司因为有些表的数据还是非常大的，其中订单表就有1亿7千多万的数据。不过公司买的是阿里的分布式DRDS，RDS分布式数据库，根据主键有100多个分库。所有我们在查业务表时，严格要求了必须带分库键，主键。而且项目里面其实都很少要写sql了，也没有联查的sql，都是封装的单表的操作。然后可能会差很多表，然后在代码里做的一步步的逻辑处理。

	做一些缓存（Mybatis,Redis），数据类型可以的话选择小的，select指定列减少IO传输量和索引覆盖

98.	ThreadLocal使用场景和内存泄漏
	ThreadLocal用来存储当前登录用户的信息，并且Spring的事务也用到threadlocal会将数据库连接对象coon存到当前对象的threadlocal中，保证该线程的多次sql操作用的是同一个数据库连接，同一个事务。
	Threadlocal的注意事项：因为ThreadLocalMap中的key是弱引用，每次发生GC时，都会被回收。而ThreadLocalMap的key就是ThreadLocal对象，所以当ThreadLocal对象被回收了，但是ThreadLocalMap的生命周期是和当前线程保持一致的，所以就造成了key没了，value还在，出现了内存泄漏（意思是这个value也没用了，但是没有被回收）。
	如何解决：每次使用完ThreadLcoal后，及时调用remove()方法释放内存空间。

99.	订单表都有哪些字段，有多少个字段，有哪些，索引
	主键id，创建时间create_date，staff_id，是否支付is_pay，城市编码city_code，省份编码，场景，渠道等等
	索引只有主键索引，和一个create_date二级索引

100.RPC和HTTP的区别

101.Redis的key和value的设计

102.常见算法的时间复杂度

103.CPU飙升排查
	CPU是计算机的核心计算资源，CPU的最小执行单元式线程。导致CPU占用飙升可能是因为线程创建的太多，导致CPU进行线程切换调度太频繁。因为线程的切换涉及到上下文的保存和新线程的调度，造成CPU飙升。也可能是有线程一直处于死循环，霸占着CPU，一直不让渡出来。
	一般可以通过如下步骤排查：
		top命令打开系统监控页面，可以按照CPU占用率做一个排序。找到占用率最高的进程。
		继续top命令，跟上进程Id参数，查看其中的线程列表，并且找到CPU利用率最高的线程。
		如果是Java线程的话，那么可以用jstack命令导出该线程的堆栈信息，进而定位到代码位置。
		

面试官你好，我叫陶兴隆，目前在南京亚信科技任职Java后端开发。
在亚信工作的时间较短，对联通订单中台这个项目的主要了解就是上游对接各个触点下来的订单，在订单中台会做一些订单拆分，报文拉齐，订单编排，数据落库后，再下发给下游的生产系统，我目前主要就是做一些迭代需求的开发。

上一家公司在南京斐哲信息科技有限公司做了将近2年的Java开发，主要的工作是参与世茂信息化管理平台项目的开发。世茂信息化管理平台主要是服务世茂物业的一个系统。我在该项目里主要负责成本控制模块和世茂业财模块的开发。其中成本控制模块是用来对地块下的各个项目做一个提前的成本编制，汇总得到来年的成本估算，通过和目前地块成本的对比来方便运维人员做后续的项目规划。世茂业财模块主要涉及到收费中心，用来管理物业各个收费项目。业财管理会管理物业下面各个收费项目产生的票据等。对账管理会根据票据和收款单提供一些核销的功能，报表管理主要就是提供各种报表的下载到处功能。
	
	
	
23-10-24 复盘一下
1.	需求上线：生产发布流程，灰度流量切入，切了一个进度时查看一下hubble的实时健康状态（健康概览，右键10s自动刷新） 第二天11点之前不能切流量
2.	分析singleTicketInfo这个RPC是否需要增加PT
	调用运输域RPC超时，运输域RPC因为查询的holo会比较慢，建议我们的RT（相应时间）设置大一点，当前设置该RPC调用的超时时间是1s
	
	评估一下总体的这个接口的RT，该RPC超时的占比
	看一下接口的性能情况：hubble--应用监控--选择服务--URL--URL（输入要观测的URL）--选择时间
	这个RPC 1s 的超时时间：是线程池的超时时间，还是RPC框架的超时间呢？是RPC框架的，而且future.get(time, unit)也有这种重载
	我们网关的超时时间是5s，观察99线，发现这个接口的RT响应时间在2s左右，最大RT是8s的样子
	这个RPC的99%的RT是800-900ms左右的，一般不会达到1s，极少情况下RT会超过1s。
	
	分析：我感觉昨天那个RPC不适合再加RT，因为这个RPC 99%的RT都是900ms以内的，一般不会达到1s超时。而且接口的RT99%已经是2s左右了，比较慢了。感觉不需要为了极少数的情况来改变原有的配置，可能还会降低原有的体验。而且这个RPC即使超时了也是弱依赖，下次刷新数据可能就很快出来了。
	用的地方再future.get()，future提交了就直接get，就相当于同步查询了。
	
	最终：在代码里把RPC超时时间改成了1500ms
	
	根据XxxFacade类名能在一个xxxRpcConfig的类中找到XxxFacade的Bean定义，其中有Timeout的配置
	
3.	qa和prod 数据变更
	直接在qa库执行修改语句会直接提示走变更工单，qa的功能自己审批即可。
	同样，生产执行修改语句也会提示走变更工单，挨个找人审批
	
	yzg-saas-metadata.saas_object_page数据修改后，要手动执行一下Redis刷新的job（yzg-saas-metadata-app的cleanSaasObjectPageJobHandler 清洗低代码平台url）
	
	变更语句：
	SET @content = (SELECT `show_content` FROM `saas_object_page` WHERE id = 157);
	UPDATE `saas_object_page` 
	SET `show_content` = (
	SELECT REPLACE(
		@content,
		'您还可以添加客户微信进行咨询',
		'您还可以添加客服微信进行咨询'  
	  )
	)
	WHERE id = 157;
	
	因为value很长导致截断，采用的上面的语句。
	
4.	导出相关接口：代码会判断字段类型是不是BigDecimal，是的话有个fenToYuan的方法，小数点进两位
	列表接口：返回数值类型，前端才会将分转化为元
	
5.	申请job权限：phantom--申请权限--历史工单--前往工单--找人审批通过

6.	DMS权限申请：
	包含hw yzg结尾的是生产从库：读权限
	包含ali yzg是生产主库：只能申请写权限（修数据），不能读（防止慢查询）
	logical库：读权限
	预发是qa库
==========================================================================
研发大致流程：
1.	打开dmpt研发管理管理平台
2.	点进待办-追加任务：后端开发（任务名称），我自己（任务所属人） 计划工时 实际开始事件 计划完成时间
3.	新增线上变更（服务端），新建分支：选择服务--分支名后缀（或者关联已有分支）
4.	上线信息：支持灰度，上线版本号（参考wiki），是否需要toMaven（是否api模块有改动，有改动需要发jar包给外部依赖），书否需要去snapshot（参考wiki）
5.	点击特性分支处的分支名：点击继承--点击部署dev
6.	dev环境测试（泳道隔离）：我新建了个自己的泳道ttxxll
7.	phantom选中要发的服务：发布dev，选中分支，分批，选择泳道（不选默认是default），

排期：
研发管理平台首页-待办任务-产线需求代办

运单域+财务域
属于财务域，目前两个域也正在拆分重构，当前的ES里面查的字段

运单管理--点击系统运单号--再来一单--保存--在对账明细出多一行记录--生成对账单--在对账单生成一条记录

提测延期：要在备注标明

qa发版：研发管理平台--版本--服务端/H5版本--（上线日期）日常发布--服务端部署--勾选需求集成到release分支--灰度QA

找异步动作的链路trace：
	1.先根据关键字到业务日志中找到打印的日志---左侧有trace可以点击直接跳到链路
	2.直接到异步接口的服务监控中看：应用监控--选择服务--Call

没有traceid接口请求怎么看链路：Hubble-->调用链--->类型URL，关键字：url:"/yzg-saas-financial-app/bill/selectCustomerList"

master分支提示有冲突：本地更新master，将master合到dev，再推dev

申请job权限：phantom--申请权限--历史工单--前往工单--找人审批通过

刷新低代码缓存：执行job 清洗低代码平台url

需求1：
运掌柜-运单管理-运单列表-导出：/yzg-saas-trans-app/ordersearch/asyncOrderSearchExport
导出的体积字段和列表录入时的提及字段小数位保持一致

导出接口--Spring事件发布器--事件监听中发mq消息--找到对应的消费者：yzg-saas-reporter-app
	
代码里有一个开关控制着走哪个集群，不同的集群发不同的topic，yzg-saas-trans-app.mq.cluster.switch集群切换开关：
	true走regional集群，topic是tp_yzg_trans_export
	false走saas集群，topic是tp_saas_trans_export
我去Lion上看了这个开关在dev关了，但是生产是开着的，所以我先在dev上把这个开关打开。
	1.到云平台（云平台的qa和dev是一个地址）：https://qa-phantom.amh-group.com/#/application/list
	2.应用列表-我的-配置所在的服务：trans-app
	3.往下拉一点-Lion配置-搜索配置名-编辑
	
怎么找消费者：yzg-saas-reporter-app
	1.MQ控制台-ACL管理-准入查询-输入topic查询
	2.hubble-应用监控-RMQ-关系
	
	
DMS权限申请：
	hw结尾的是生产从库：读权限
	ali是生产主库：只能申请写权限（修数据），不能读（防止慢查询）
	logical库：读权限
	预发是qa库
	
重启服务：
	phantom找到对应的服务--机器&容器--重启
	
yzg-saas-reporter-app找到监听tp_yzg_trans_export这个topic的地方，发现代码里又发送一个内部同步MQ消息。
根据上面的开关，走不同的集群，发送不同的topic：
	true走reginal集群：tp_yzg_tms_reporter_async_export_topic
	false走saas集群：tp_saas_tms_reporter_async_export_topic
	因为是内部同步消息，直接在找yzg-saas-reporter-app到监听tp_yzg_tms_reporter_async_export_topic的位置，最后找到了导出的代码

找到查询运单数据的地方，发现通过RPC又调回到yzg-saas-trans-app了
	"bizcode":"order_search_list_head"对应着这个OrderExportDataFetchServiceImpl



需求2：对账明细页面增加单票毛利等字段
1.目前还不是需求owner，从dmpt研发管理平台找到对应需求：需求-需求池-池名称TMS-带规划找到需求-后续可以让领导将需求转给我
单票毛利、单票收入、单票成本

财务管理-客户对账-对账明细

查看列表页面的key：点击字段过滤按钮--有一个/yzg-saas-common-setting-app/table/header/source接口--入参就是列表页面的key

dev环境 saas-common-setting tableHeaderReloadHandler这个job在跑，刷新设置到表头到Redis，因为我们和saas用的一个Redis集群，所以我们也相当于刷新了

两个页面：
列表financial_customer_list_v2： /yzg-saas-financial-app/bill/selectCustomerList  
对账单详情列表financial_customer_statement_detail_v2： /yzg-saas-financial-app/bill/selectCustomerList

看一下接口的性能情况：hubble--应用监控--选择服务--URL--URL（输入要观测的URL）--选择时间

单票收入，单票成本，单票毛利，单票毛利率
    private BigDecimal singleTicketProfit;
    private BigDecimal singleTicketIncome;
    private BigDecimal singleTicketCost;


单票收入，单票成本，单票毛利，单票毛利率

合计的问题：
	比如列表数据有多个分页，那么合计字段是合计全部数据的。如果某个字段是来自外部通过RPC调用的，那么这个字段的聚合怎么做？
	因为该字段不是在当前域维护的，所以进行聚合操作的话，就需要考虑怎么做，适不适合在我们这边做，要不要做聚合计算。
	
导出：/yzg-saas-financial-app/async/export/dispatcher
	{
	  "bizCode": "financial_customer_list_v2",
	  "fileName": "客户对账明细",
	  "queryField": "{\"billType\":1,\"statementType\":1,\"menuCode\":170110,\"carriageTime\":[\"2023-09-16 00:00:00\",\"2023-10-16 23:59:59\"],\"operatorCharType\":\"GT\",\"orderMap\":{},\"searchMap\":{}}"
	}

	com.saas.yzg.financial.server.export.header.customer.CustomerStatementDetailHeaderV2#getExportInfo
	{
	  "bizCode": "financial_customer_statement_detail_v2",
	  "fileName": "未指定客户客户对账单详情_ZD20231013000002",
	  "queryField": "{\"reconcileId\":\"910250572027854848\"}"
	}
	topic：tp_yzg_tms_reporter_async_export_financial_topic
	
	
	两个时间字段：评估需不需要检索（是不是跨域），不做检索
	
需求3：Lion迁移：
	ConfigCache.getInstance().getProperty("es.es7-saas-customer.host");
	@ConfigKey
	@ConfigurationValue
	saas-tms-reporter-app
	saas-analysis-app

	yzg-saas-reporter-app：代码无需改动


===========================================================================


1.	客户付款申请单列表满运宝tab页反馈无查看权限
	路径：财务管理--付款申请单列表--满运宝支付：yzg-saas-financial-app/payment/apply/list/myb
	报错：无运费申请单查询权限，请分配权限后再查看
	公司名称：上海凌归物流有限公司
	账号：1312065988
	
	函谷关-用户查询：https://hango.amh-group.com/#/monitor-request
	输入手机号，用户身份选择TMS商户，没查到信息。
	
	运掌柜-客户管理-后台：https://boss.amh-group.com/region-yzg-crm/#/amis/view/tmsCrm-crmlist
	输入客户名称：上海凌归物流有限公司，查询得到租户id
	
	Hubble查看链路：https://hubble.amh-group.com/#/logcenter/elasticsearch-biz?domain=hubble&logSearchType=1&project=&roomName=default&query=&map%5Bpro%5D=hubble&map%5Bip%5D=sche&startTime=1630634059000&endTime=1630635858999&currentTime=30m
	应用监控-搜索框中输入接口对应的服务名：yzg-saas-financial-app
	日志中心-网管日志：在用户ID处输入刚才查到的租户ID，请求URL输入接口地址后缀，日期选择调用日期，查询。
	问题大概是下午5点之前发生，查看附近的日志：在详情处找到一条相应和报错一致，查看链路。
	在链路分析和原始链路里面找对应的RPC调用的方法名等关键字
	
	1.列表查看是通过RPC调用满运宝的接口，在满运宝那里的权限判断没通过。
	2.运掌柜加了相应的权限，同步权限到满运宝对应的权限：但是没有同步成功。
	
2.	异步同步动作（调用RPC）链路：查看调用tmsSyncUser的链路
	应用监控-Call-方法请选择-输入tmsSyncUser-勾选-汇总
	
3.	客户在运单列表和司机付款申请页面发起司机付款申请时提示“分段付数据异常”：操作支付时提示分段支付数据异常
	路径：财务管理--付款管理--司机付款
	
	提交增补协议：修改了待支付金额，ES里面的数据更新成功了，DB里面的数据还是旧数据
	
	看看提交增补协议接口：/yzg-saas-trans-app/contract/submitContractSupplement里面有没有更新DB和同步ES的逻辑
	
	提交了增补协议后，还需要司机确认才算协议增补成功。
	
4.	RMQ消费消息：99线（99%）的RT是3103.88ms，导致binlog集群消息堆积
	从链路上看：加分布式锁，sleep（因为同步ES时，需要查从库，因为主从延迟慢的奖金1s，所以sleep了1s）：大致消耗了3s	
	假设有6个线程去更新同一个记录（同一个id，结果可能是不一样的），根据binlog去同步ES，由分布式所控制。
	都去抢分布式锁，因为id一样导致redis的key是同一个（key:lock_TMS_binlog_sync:saas_financial_new_bills_15_id_908072769558888448），所以这6个线程只能串行。那么最后一个线程肯定很慢
	
	所以这个redis的key是不是设计不合理？因为会存在多个线程修改同一个id，而我们只想锁住这个binlog，但是这个记录的id会产生多个binlog。
		想错了，如果只锁住当前这个binlog，那么相当于每个binlog都会直接抢到锁，直接执行。加入有V1，V2两个更新操作，同步V1时假设发生了FullGC，V2同步完了，
		V1继续同步。导致V2被V1覆盖，所以有并发问题。
		如果锁id，那么假设V2先抢到锁，查询库得到V2数据，同步到ES，释放锁。V1抢到锁，查询DB出来的还是V2，再更新一次。虽然重复的动作，但是结果正确。
	多个对于这个id的更新动作，消费binlog，是怎么做到顺序性的？比如before值吗
	
	
5.	调用运输域RPC超时，运输域RPC因为查询的holo会比较慢，建议我们的RT（相应时间）设置大一点，当前设置该RPC调用的超时时间是1s
	
	评估一下总体的这个接口的RT，该RPC超时的占比
	这个RPC 1s 的超时时间：是线程池的超时时间，还是RPC框架的超时间呢？是RPC框架的，而且future.get(time, unit)也有这种重载
	我们网关的超时时间是5s，观察99线，发现这个接口的RT响应时间在2s左右，最大RT是8s的样子
	这个RPC的99%的RT是800-900ms左右的，一般不会达到1s，极少情况下RT会超过1s。
	
	我感觉昨天那个RPC不适合再加RT，因为这个RPC 99%的RT都是900ms以内的，一般不会达到1s超时。而且接口的RT99%已经是2s左右了，比较慢了。感觉不需要为了极少数的情况来改变原有的配置，可能还会降低原有的体验。而且这个RPC即使超时了也是弱依赖，下次刷新数据可能就很快出来了。
	用的地方再future.get()，future提交了就直接get，就相当于同步查询了。	
	
	
	
	

	

	
	